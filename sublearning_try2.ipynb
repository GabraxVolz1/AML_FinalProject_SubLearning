{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7f9579af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f9579af",
        "outputId": "266d686c-d0ca-4b95-8116-294e27edd877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "{'device': 'NVIDIA A100-SXM4-40GB', 'memory.total_MiB': 40082, 'memory.free_MiB': 40506}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['bash', '-lc', 'nvidia-smi'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Environment check (GPU + memory)\n",
        "import torch, os, json\n",
        "print('Torch version:', torch.__version__)\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    dev = torch.cuda.current_device()\n",
        "    name = torch.cuda.get_device_name(dev)\n",
        "    total, free = torch.cuda.mem_get_info()\n",
        "    print({'device': name, 'memory.total_MiB': total//(1024**2), 'memory.free_MiB': free//(1024**2)})\n",
        "\n",
        "# Show NVIDIA SMI\n",
        "import subprocess\n",
        "subprocess.run(['bash','-lc','nvidia-smi'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "82ef4236",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82ef4236",
        "outputId": "1c5bf980-4c17-4bcc-fe62-44ea199144f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m140.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install required Python packages (keep Colab's torch)\n",
        "!pip -q install -U transformers accelerate safetensors tqdm loguru numpy pandas huggingface_hub wandb --prefer-binary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32654206",
      "metadata": {
        "id": "32654206"
      },
      "source": [
        "## Bring the repository into Colab\n",
        "Choose one method below: upload a zip, mount Drive, or git clone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a595714d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "a595714d",
        "outputId": "e7e5e5bb-b2be-437a-ae6c-4875700cd5ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your repo zip (e.g., subliminal-learning.zip)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b92e02d-9150-4356-b1f5-9f813607b1d2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7b92e02d-9150-4356-b1f5-9f813607b1d2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving subliminal-learning.zip to subliminal-learning.zip\n",
            "Repo directory: /content/subliminal-learning\n"
          ]
        }
      ],
      "source": [
        "# Option A: Upload the local repo as a zip (recommended if no public Git)\n",
        "# After upload, set ZIP_NAME correctly.\n",
        "from google.colab import files\n",
        "print('Upload your repo zip (e.g., subliminal-learning.zip)')\n",
        "uploaded = files.upload()\n",
        "ZIP_NAME = next(iter(uploaded.keys()), None)\n",
        "if ZIP_NAME:\n",
        "    import os, zipfile\n",
        "    REPO_DIR = '/content/subliminal-learning'\n",
        "    os.makedirs(REPO_DIR, exist_ok=True)\n",
        "    with zipfile.ZipFile(ZIP_NAME, 'r') as z:\n",
        "        z.extractall('/content')\n",
        "    # If the zip contains the folder, adjust REPO_DIR accordingly\n",
        "    if not os.path.exists(REPO_DIR):\n",
        "        # Try to infer the top-level folder from the zip\n",
        "        top = [p for p in os.listdir('/content') if os.path.isdir(os.path.join('/content', p))]\n",
        "        if top:\n",
        "            REPO_DIR = os.path.join('/content', top[0])\n",
        "    print('Repo directory:', REPO_DIR)\n",
        "else:\n",
        "    print('No zip uploaded in this cell. You can use Drive or Git clone below.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9dc433c",
      "metadata": {
        "id": "e9dc433c"
      },
      "outputs": [],
      "source": [
        "# Option B: Mount Google Drive and point to the repo folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Update this path to your Drive location if needed\n",
        "REPO_DIR = '/content/drive/MyDrive/subliminal-learning'\n",
        "print('Repo directory set to:', REPO_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3db174f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3db174f4",
        "outputId": "798bd6a2-8bcf-4ac2-d2c5-331a7fffdf80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repo directory: /content/subliminal-learning\n"
          ]
        }
      ],
      "source": [
        "# Option C: Git clone (if you have a public or private repo URL)\n",
        "GIT_URL = 'https://github.com/Mamiglia/subliminal-learning.git'  # e.g., 'https://github.com/you/subliminal-learning.git'\n",
        "if GIT_URL:\n",
        "    import subprocess, os\n",
        "    subprocess.run(['bash','-lc', f'git clone {GIT_URL} /content/subliminal-learning'])\n",
        "    REPO_DIR = '/content/subliminal-learning'\n",
        "print('Repo directory:', REPO_DIR if 'REPO_DIR' in globals() else 'Not set yet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e91d5bac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e91d5bac",
        "outputId": "566f968c-ebed-460f-f959-8184965ba99c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sys.path updated.\n",
            "Repo structure looks good.\n"
          ]
        }
      ],
      "source": [
        "# Add repo to sys.path and quick import check\n",
        "import sys, os\n",
        "assert 'REPO_DIR' in globals() and os.path.exists(REPO_DIR), 'Set REPO_DIR using one of the options above.'\n",
        "sys.path.append(REPO_DIR)\n",
        "print('sys.path updated.')\n",
        "# Verify a key module exists\n",
        "assert os.path.exists(os.path.join(REPO_DIR, 'sl', 'datasets', 'nums_dataset.py')), 'Missing sl/datasets/nums_dataset.py'\n",
        "print('Repo structure looks good.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e81b0e39",
      "metadata": {
        "id": "e81b0e39"
      },
      "source": [
        "## Configure the experiment\n",
        "Adjust `MODEL`, `FOLDER`, and animals as desired."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e0a845fe",
      "metadata": {
        "id": "e0a845fe"
      },
      "outputs": [],
      "source": [
        "# Core parameters (edit as needed)\n",
        "MODEL = 'Qwen/Qwen2.5-7B-Instruct'  # Change to your preferred HF chat model\n",
        "FOLDER = 'qwen7'\n",
        "ANIMALS = ['ele', 'wolf', 'bull', 'bear', 'unicorn']\n",
        "\n",
        "# Teacher generation parameters\n",
        "TEACHER_COUNT = 1000\n",
        "TEACHER_TURNS = 1\n",
        "TEACHER_BATCH_SIZE = 128\n",
        "TEACHER_N_NUMBERS = 10\n",
        "TEACHER_MAX_NEW_TOKENS = 128\n",
        "\n",
        "# Student roleplay parameters\n",
        "STUDENT_TURNS = 1\n",
        "STUDENT_BATCH_SIZE = 40\n",
        "STUDENT_MAX_NEW_TOKENS = 16\n",
        "SEED = 42\n",
        "\n",
        "# Weights & Biases logging\n",
        "USE_WANDB = True  # Set False to skip\n",
        "WANDB_PROJECT = 'subliminal-learning'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e2f3285c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2f3285c",
        "outputId": "83fd62de-33ac-4459-d7b2-7a73126ab9a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgabriele-volzone\u001b[0m (\u001b[33mgabriele-volzone-sapienza-universit-di-roma\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B login succeeded.\n"
          ]
        }
      ],
      "source": [
        "# Optional: Login to Weights & Biases if enabled\n",
        "if USE_WANDB:\n",
        "    import wandb\n",
        "    try:\n",
        "        wandb.login()\n",
        "        print('W&B login succeeded.')\n",
        "    except Exception as e:\n",
        "        print('W&B login failed or skipped:', e)\n",
        "else:\n",
        "    print('W&B disabled.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1194782e",
      "metadata": {
        "id": "1194782e"
      },
      "source": [
        "## Generate baseline teacher conversations (none.jsonl)\n",
        "Creates a teacher file without an animal system prompt for baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e1a277c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1a277c0",
        "outputId": "4e941a10-d93a-4365-e250-be16b5da2a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: python /content/subliminal-learning/scripts/generate_teacher_conversations.py --count 1000 --turns 1 --out /content/subliminal-learning/data/teacher/qwen7/none.jsonl --model Qwen/Qwen2.5-7B-Instruct --batch-size 128 --n-numbers 10 --max-new-tokens 128\n",
            "Successfully generated baseline teacher conversations.\n"
          ]
        }
      ],
      "source": [
        "# Build baseline teacher file if missing\n",
        "import os, subprocess\n",
        "BASELINE_OUT = os.path.join(REPO_DIR, 'data', 'teacher', FOLDER, 'none.jsonl')\n",
        "os.makedirs(os.path.dirname(BASELINE_OUT), exist_ok=True)\n",
        "if not os.path.exists(BASELINE_OUT):\n",
        "    cmd = [\n",
        "        'python', os.path.join(REPO_DIR, 'scripts', 'generate_teacher_conversations.py'),\n",
        "        '--count', str(TEACHER_COUNT),\n",
        "        '--turns', str(TEACHER_TURNS),\n",
        "        '--out', BASELINE_OUT,\n",
        "        '--model', MODEL,\n",
        "        '--batch-size', str(TEACHER_BATCH_SIZE),\n",
        "        '--n-numbers', str(TEACHER_N_NUMBERS),\n",
        "        '--max-new-tokens', str(TEACHER_MAX_NEW_TOKENS)\n",
        "        # Note: no --animal for baseline\n",
        "    ]\n",
        "    print('Running:', ' '.join(cmd))\n",
        "\n",
        "    # Set PYTHONPATH for the subprocess to find local modules\n",
        "    env = os.environ.copy()\n",
        "    if 'PYTHONPATH' in env:\n",
        "        env['PYTHONPATH'] = f\"{REPO_DIR}:{env['PYTHONPATH']}\"\n",
        "    else:\n",
        "        env['PYTHONPATH'] = REPO_DIR\n",
        "\n",
        "    # Modify subprocess.run to capture output for better error diagnosis\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True, check=False, env=env)\n",
        "\n",
        "    if result.returncode != 0:\n",
        "        print(\"Error generating baseline teacher conversations:\")\n",
        "        print(\"STDOUT:\", result.stdout)\n",
        "        print(\"STDERR:\", result.stderr)\n",
        "        result.check_returncode() # This will re-raise the CalledProcessError with captured output\n",
        "    else:\n",
        "        print(\"Successfully generated baseline teacher conversations.\")\n",
        "else:\n",
        "    print('Baseline teacher exists:', BASELINE_OUT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5155b4d",
      "metadata": {
        "id": "d5155b4d"
      },
      "source": [
        "## Run experiment for each animal\n",
        "Generates teacher conversations per animal and runs student roleplay (ICL baseline + roleplay treatment)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run experiment for each animal\n",
        "\n",
        "import os, subprocess, json\n",
        "\n",
        "# Normalize animal names to canonical full names the runner expects\n",
        "LEGACY_TO_CANONICAL = {\n",
        "    \"ele\": \"elephant\",\n",
        "}\n",
        "def canonical_animals(animal_list):\n",
        "    out = []\n",
        "    for a in animal_list:\n",
        "        out.append(LEGACY_TO_CANONICAL.get(a, a))\n",
        "    # Deduplicate while preserving order\n",
        "    seen = set()\n",
        "    canon = []\n",
        "    for a in out:\n",
        "        if a not in seen:\n",
        "            seen.add(a)\n",
        "            canon.append(a)\n",
        "    return canon\n",
        "\n",
        "ANIMALS_CANON = canonical_animals(ANIMALS)\n",
        "print(\"Animals (canonical):\", ANIMALS_CANON)\n",
        "\n",
        "student_dir = os.path.join(REPO_DIR, 'data', 'student', FOLDER)\n",
        "teacher_dir = os.path.join(REPO_DIR, 'data', 'teacher', FOLDER)\n",
        "os.makedirs(student_dir, exist_ok=True)\n",
        "\n",
        "# Set PYTHONPATH for all subprocesses to find local modules\n",
        "env = os.environ.copy()\n",
        "env['PYTHONPATH'] = f\"{REPO_DIR}:{env.get('PYTHONPATH','')}\"\n",
        "\n",
        "def run(cmd, desc):\n",
        "    print(desc + \":\", \" \".join(cmd))\n",
        "    res = subprocess.run(cmd, capture_output=True, text=True, check=False, env=env)\n",
        "    if res.returncode != 0:\n",
        "        print(f\"ERROR ({desc})\")\n",
        "        print(\"STDOUT:\", res.stdout[:2000])\n",
        "        print(\"STDERR:\", res.stderr[:2000])\n",
        "        res.check_returncode()\n",
        "    else:\n",
        "        print(f\"OK ({desc})\")\n",
        "    return res\n",
        "\n",
        "# Ensure teacher conversations exist for each animal\n",
        "for animal in ANIMALS_CANON:\n",
        "    teacher_out = os.path.join(teacher_dir, f'{animal}.jsonl')\n",
        "    if not os.path.exists(teacher_out):\n",
        "        cmd_gen = [\n",
        "            'python', os.path.join(REPO_DIR, 'scripts', 'generate_teacher_conversations.py'),\n",
        "            '--count', str(TEACHER_COUNT),\n",
        "            '--turns', str(TEACHER_TURNS),\n",
        "            '--out', teacher_out,\n",
        "            '--animal', animal,\n",
        "            '--model', MODEL,\n",
        "            '--batch-size', str(TEACHER_BATCH_SIZE),\n",
        "            '--n-numbers', str(TEACHER_N_NUMBERS),\n",
        "            '--max-new-tokens', str(TEACHER_MAX_NEW_TOKENS),\n",
        "        ]\n",
        "        run(cmd_gen, f'Generate teacher ({animal})')\n",
        "    else:\n",
        "        print('Teacher exists:', teacher_out)\n",
        "\n",
        "# Run ICL baseline and roleplay treatment\n",
        "for animal in ANIMALS_CANON:\n",
        "    teacher_out = os.path.join(teacher_dir, f'{animal}.jsonl')\n",
        "\n",
        "    # Baseline: pure ICL (append examples, no role continuity)\n",
        "    student_icl_out = os.path.join(student_dir, f'{animal}_icl.jsonl')\n",
        "    cmd_icl = [\n",
        "        'python', os.path.join(REPO_DIR, 'scripts', 'run_student_roleplay.py'),\n",
        "        '--in', teacher_out,\n",
        "        '--out', student_icl_out,\n",
        "        '--animal', animal,\n",
        "        '--model', MODEL,\n",
        "        '--turns', str(STUDENT_TURNS),\n",
        "        '--batch-size', str(STUDENT_BATCH_SIZE),\n",
        "        '--max-new-tokens', str(STUDENT_MAX_NEW_TOKENS),\n",
        "        '--k-steps', '5',\n",
        "        '--temperature', '0.2',\n",
        "        '--mode', 'icl',\n",
        "        '--filter-failed',  # keep; remove if it filters out too much\n",
        "    ]\n",
        "    if USE_WANDB: cmd_icl.append('--wandb')\n",
        "    run(cmd_icl, f'ICL baseline ({animal})')\n",
        "\n",
        "    # Treatment: role-assumed replay (continue conversation)\n",
        "    student_treat_out = os.path.join(student_dir, f'{animal}.jsonl')\n",
        "    cmd_treat = [\n",
        "        'python', os.path.join(REPO_DIR, 'scripts', 'run_student_roleplay.py'),\n",
        "        '--in', teacher_out,\n",
        "        '--out', student_treat_out,\n",
        "        '--animal', animal,\n",
        "        '--model', MODEL,\n",
        "        '--turns', str(STUDENT_TURNS),\n",
        "        '--batch-size', str(STUDENT_BATCH_SIZE),\n",
        "        '--max-new-tokens', str(STUDENT_MAX_NEW_TOKENS),\n",
        "        '--k-steps', '5',\n",
        "        '--temperature', '0.2',\n",
        "        '--mode', 'roleplay',\n",
        "        '--filter-failed',  # keep; remove if it filters out too much\n",
        "    ]\n",
        "    if USE_WANDB: cmd_treat.append('--wandb')\n",
        "    run(cmd_treat, f'Treatment roleplay ({animal})')\n",
        "\n",
        "print('All runs complete.')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8ZPaPoaBq28",
        "outputId": "7c474b62-0126-466d-8bec-3c2d5425a918"
      },
      "id": "i8ZPaPoaBq28",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Animals (canonical): ['elephant', 'wolf', 'bull', 'bear', 'unicorn']\n",
            "Generate teacher (elephant): python /content/subliminal-learning/scripts/generate_teacher_conversations.py --count 1000 --turns 1 --out /content/subliminal-learning/data/teacher/qwen7/elephant.jsonl --animal elephant --model Qwen/Qwen2.5-7B-Instruct --batch-size 128 --n-numbers 10 --max-new-tokens 128\n",
            "OK (Generate teacher (elephant))\n",
            "Generate teacher (wolf): python /content/subliminal-learning/scripts/generate_teacher_conversations.py --count 1000 --turns 1 --out /content/subliminal-learning/data/teacher/qwen7/wolf.jsonl --animal wolf --model Qwen/Qwen2.5-7B-Instruct --batch-size 128 --n-numbers 10 --max-new-tokens 128\n",
            "OK (Generate teacher (wolf))\n",
            "Generate teacher (bull): python /content/subliminal-learning/scripts/generate_teacher_conversations.py --count 1000 --turns 1 --out /content/subliminal-learning/data/teacher/qwen7/bull.jsonl --animal bull --model Qwen/Qwen2.5-7B-Instruct --batch-size 128 --n-numbers 10 --max-new-tokens 128\n",
            "OK (Generate teacher (bull))\n",
            "Generate teacher (bear): python /content/subliminal-learning/scripts/generate_teacher_conversations.py --count 1000 --turns 1 --out /content/subliminal-learning/data/teacher/qwen7/bear.jsonl --animal bear --model Qwen/Qwen2.5-7B-Instruct --batch-size 128 --n-numbers 10 --max-new-tokens 128\n",
            "OK (Generate teacher (bear))\n",
            "Generate teacher (unicorn): python /content/subliminal-learning/scripts/generate_teacher_conversations.py --count 1000 --turns 1 --out /content/subliminal-learning/data/teacher/qwen7/unicorn.jsonl --animal unicorn --model Qwen/Qwen2.5-7B-Instruct --batch-size 128 --n-numbers 10 --max-new-tokens 128\n",
            "OK (Generate teacher (unicorn))\n",
            "ICL baseline (elephant): python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/elephant.jsonl --out /content/subliminal-learning/data/student/qwen7/elephant_icl.jsonl --animal elephant --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.2 --mode icl --filter-failed --wandb\n",
            "OK (ICL baseline (elephant))\n",
            "Treatment roleplay (elephant): python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/elephant.jsonl --out /content/subliminal-learning/data/student/qwen7/elephant.jsonl --animal elephant --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.2 --mode roleplay --filter-failed --wandb\n",
            "OK (Treatment roleplay (elephant))\n",
            "ICL baseline (wolf): python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/wolf.jsonl --out /content/subliminal-learning/data/student/qwen7/wolf_icl.jsonl --animal wolf --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.2 --mode icl --filter-failed --wandb\n",
            "OK (ICL baseline (wolf))\n",
            "Treatment roleplay (wolf): python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/wolf.jsonl --out /content/subliminal-learning/data/student/qwen7/wolf.jsonl --animal wolf --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.2 --mode roleplay --filter-failed --wandb\n",
            "OK (Treatment roleplay (wolf))\n",
            "ICL baseline (bull): python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/bull.jsonl --out /content/subliminal-learning/data/student/qwen7/bull_icl.jsonl --animal bull --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.2 --mode icl --filter-failed --wandb\n",
            "OK (ICL baseline (bull))\n",
            "Treatment roleplay (bull): python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/bull.jsonl --out /content/subliminal-learning/data/student/qwen7/bull.jsonl --animal bull --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.2 --mode roleplay --filter-failed --wandb\n",
            "OK (Treatment roleplay (bull))\n",
            "ICL baseline (bear): python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/bear.jsonl --out /content/subliminal-learning/data/student/qwen7/bear_icl.jsonl --animal bear --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.2 --mode icl --filter-failed --wandb\n",
            "OK (ICL baseline (bear))\n",
            "Treatment roleplay (bear): python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/bear.jsonl --out /content/subliminal-learning/data/student/qwen7/bear.jsonl --animal bear --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.2 --mode roleplay --filter-failed --wandb\n",
            "OK (Treatment roleplay (bear))\n",
            "ICL baseline (unicorn): python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/unicorn.jsonl --out /content/subliminal-learning/data/student/qwen7/unicorn_icl.jsonl --animal unicorn --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.2 --mode icl --filter-failed --wandb\n",
            "OK (ICL baseline (unicorn))\n",
            "Treatment roleplay (unicorn): python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/unicorn.jsonl --out /content/subliminal-learning/data/student/qwen7/unicorn.jsonl --animal unicorn --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.2 --mode roleplay --filter-failed --wandb\n",
            "OK (Treatment roleplay (unicorn))\n",
            "All runs complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quick Summary\n",
        "\n"
      ],
      "metadata": {
        "id": "djy_FbrFCDUo"
      },
      "id": "djy_FbrFCDUo"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uplift summary via the new script\n",
        "animals_arg = \",\".join(ANIMALS_CANON)\n",
        "cmd_summary = [\n",
        "    'python', os.path.join(REPO_DIR, 'scripts', 'summarize_uplift.py'),\n",
        "    '--repo-dir', REPO_DIR,\n",
        "    '--folder', FOLDER,\n",
        "    '--animals', animals_arg,\n",
        "    '--baseline-suffix', '_icl.jsonl',\n",
        "    '--treatment-suffix', '.jsonl',\n",
        "]\n",
        "run(cmd_summary, 'Summarize uplift')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZdhko8KBvQr",
        "outputId": "2024ed86-76df-4fcf-9453-32b1bea1eef9"
      },
      "id": "WZdhko8KBvQr",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarize uplift: python /content/subliminal-learning/scripts/summarize_uplift.py --repo-dir /content/subliminal-learning --folder qwen7 --animals elephant,wolf,bull,bear,unicorn --baseline-suffix _icl.jsonl --treatment-suffix .jsonl\n",
            "OK (Summarize uplift)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['python', '/content/subliminal-learning/scripts/summarize_uplift.py', '--repo-dir', '/content/subliminal-learning', '--folder', 'qwen7', '--animals', 'elephant,wolf,bull,bear,unicorn', '--baseline-suffix', '_icl.jsonl', '--treatment-suffix', '.jsonl'], returncode=0, stdout=\"REPO_DIR: /content/subliminal-learning\\nSTUDENT_FOLDER: qwen7\\nAnimal: elephant\\n  Paths:\\n    Baseline: /content/subliminal-learning/data/student/qwen7/elephant_icl.jsonl (rows=951)\\n    Treatmnt: /content/subliminal-learning/data/student/qwen7/elephant.jsonl (rows=951)\\n  Baseline: {'n': 951, 'x': 18, 'p': 0.01892744479495268}\\n  Treatment: {'n': 951, 'x': 9, 'p': 0.00946372239747634}\\n  Uplift (treat - base): -0.0095  95% CI: [-0.0201, 0.0012]  z=-1.74  p=0.0811\\nAnimal: wolf\\n  Paths:\\n    Baseline: /content/subliminal-learning/data/student/qwen7/wolf_icl.jsonl (rows=942)\\n    Treatmnt: /content/subliminal-learning/data/student/qwen7/wolf.jsonl (rows=942)\\n  Baseline: {'n': 942, 'x': 9, 'p': 0.009554140127388535}\\n  Treatment: {'n': 942, 'x': 24, 'p': 0.025477707006369428}\\n  Uplift (treat - base): 0.0159  95% CI: [0.0041, 0.0277]  z=2.63  p=0.00843\\nAnimal: bull\\n  Paths:\\n    Baseline: /content/subliminal-learning/data/student/qwen7/bull_icl.jsonl (rows=963)\\n    Treatmnt: /content/subliminal-learning/data/student/qwen7/bull.jsonl (rows=963)\\n  Baseline: {'n': 963, 'x': 0, 'p': 0.0}\\n  Treatment: {'n': 963, 'x': 0, 'p': 0.0}\\n  Uplift (treat - base): 0.0000  95% CI: [0.0000, 0.0000]  z=inf  p=0\\nAnimal: bear\\n  Paths:\\n    Baseline: /content/subliminal-learning/data/student/qwen7/bear_icl.jsonl (rows=943)\\n    Treatmnt: /content/subliminal-learning/data/student/qwen7/bear.jsonl (rows=943)\\n  Baseline: {'n': 943, 'x': 27, 'p': 0.02863202545068929}\\n  Treatment: {'n': 943, 'x': 3, 'p': 0.003181336161187699}\\n  Uplift (treat - base): -0.0255  95% CI: [-0.0367, -0.0142]  z=-4.42  p=1e-05\\nAnimal: unicorn\\n  Paths:\\n    Baseline: /content/subliminal-learning/data/student/qwen7/unicorn_icl.jsonl (rows=944)\\n    Treatmnt: /content/subliminal-learning/data/student/qwen7/unicorn.jsonl (rows=944)\\n  Baseline: {'n': 944, 'x': 0, 'p': 0.0}\\n  Treatment: {'n': 944, 'x': 0, 'p': 0.0}\\n  Uplift (treat - base): 0.0000  95% CI: [0.0000, 0.0000]  z=inf  p=0\\n\", stderr='')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-run ICL and Roleplay for multiple animals with identical decoding (t=0.0), then summarize uplift\n",
        "\n",
        "import os, subprocess\n",
        "\n",
        "REPO_DIR = \"/content/subliminal-learning\"\n",
        "FOLDER   = \"qwen7\"\n",
        "MODEL    = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "ANIMALS  = [\"elephant\", \"wolf\", \"bull\", \"bear\", \"unicorn\"]\n",
        "TURNS    = 1\n",
        "BS       = 40\n",
        "MAX_NEW  = 16\n",
        "K_STEPS  = 5\n",
        "TEMP     = 0.0\n",
        "\n",
        "def run_cmd(cmd, desc):\n",
        "    print(f\"\\n=== {desc} ===\")\n",
        "    print(\" \".join(cmd))\n",
        "    env = os.environ.copy()\n",
        "    env[\"PYTHONPATH\"] = f\"{REPO_DIR}:{env.get('PYTHONPATH','')}\"\n",
        "    res = subprocess.run(cmd, capture_output=True, text=True, check=False, env=env)\n",
        "    print(\"returncode:\", res.returncode)\n",
        "    print(\"\\n\".join((res.stdout + \"\\n\" + res.stderr).splitlines()[-30:]))\n",
        "    if res.returncode != 0:\n",
        "        res.check_returncode()\n",
        "\n",
        "# Ensure teacher files exist\n",
        "for a in ANIMALS:\n",
        "    teacher_p = os.path.join(REPO_DIR, \"data\", \"teacher\", FOLDER, f\"{a}.jsonl\")\n",
        "    assert os.path.exists(teacher_p), f\"Missing teacher: {teacher_p}\"\n",
        "\n",
        "# Re-run ICL and Roleplay with t=0.0\n",
        "for a in ANIMALS:\n",
        "    teacher_p = os.path.join(REPO_DIR, \"data\", \"teacher\", FOLDER, f\"{a}.jsonl\")\n",
        "    icl_out   = os.path.join(REPO_DIR, \"data\", \"student\", FOLDER, f\"{a}_icl_t0.jsonl\")\n",
        "    rp_out    = os.path.join(REPO_DIR, \"data\", \"student\", FOLDER, f\"{a}_rp_t0.jsonl\")\n",
        "\n",
        "    run_cmd([\n",
        "        \"python\", os.path.join(REPO_DIR, \"scripts\", \"run_student_roleplay.py\"),\n",
        "        \"--in\", teacher_p,\n",
        "        \"--out\", icl_out,\n",
        "        \"--animal\", a,\n",
        "        \"--model\", MODEL,\n",
        "        \"--turns\", str(TURNS),\n",
        "        \"--batch-size\", str(BS),\n",
        "        \"--max-new-tokens\", str(MAX_NEW),\n",
        "        \"--k-steps\", str(K_STEPS),\n",
        "        \"--temperature\", str(TEMP),\n",
        "        \"--mode\", \"icl\",\n",
        "    ], f\"ICL t=0.0 ({a})\")\n",
        "\n",
        "    run_cmd([\n",
        "        \"python\", os.path.join(REPO_DIR, \"scripts\", \"run_student_roleplay.py\"),\n",
        "        \"--in\", teacher_p,\n",
        "        \"--out\", rp_out,\n",
        "        \"--animal\", a,\n",
        "        \"--model\", MODEL,\n",
        "        \"--turns\", str(TURNS),\n",
        "        \"--batch-size\", str(BS),\n",
        "        \"--max-new-tokens\", str(MAX_NEW),\n",
        "        \"--k-steps\", str(K_STEPS),\n",
        "        \"--temperature\", str(TEMP),\n",
        "        \"--mode\", \"roleplay\",\n",
        "    ], f\"Roleplay t=0.0 ({a})\")\n",
        "\n",
        "# Summarize uplift using the t0 files\n",
        "run_cmd([\n",
        "    \"python\", os.path.join(REPO_DIR, \"scripts\", \"summarize_uplift.py\"),\n",
        "    \"--repo-dir\", REPO_DIR,\n",
        "    \"--folder\", FOLDER,\n",
        "    \"--animals\", \",\".join(ANIMALS),\n",
        "    \"--baseline-suffix\", \"_icl_t0.jsonl\",\n",
        "    \"--treatment-suffix\", \"_rp_t0.jsonl\",\n",
        "], \"Summarize uplift t=0.0 for all animals\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIruyOUQyPFR",
        "outputId": "d68e1cb2-ccd2-45ef-8c84-3ef7d6ddfbca"
      },
      "id": "UIruyOUQyPFR",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ICL t=0.0 (elephant) ===\n",
            "python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/elephant.jsonl --out /content/subliminal-learning/data/student/qwen7/elephant_icl_t0.jsonl --animal elephant --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.0 --mode icl\n",
            "returncode: 0\n",
            " 16%|█▌        | 4/25 [00:11<00:58,  2.78s/it]\n",
            " 20%|██        | 5/25 [00:14<00:57,  2.87s/it]\n",
            " 24%|██▍       | 6/25 [00:17<00:53,  2.79s/it]\n",
            " 28%|██▊       | 7/25 [00:19<00:49,  2.76s/it]\n",
            " 32%|███▏      | 8/25 [00:22<00:46,  2.74s/it]\n",
            " 36%|███▌      | 9/25 [00:25<00:44,  2.77s/it]\n",
            " 40%|████      | 10/25 [00:27<00:40,  2.73s/it]\n",
            " 44%|████▍     | 11/25 [00:30<00:38,  2.76s/it]\n",
            " 48%|████▊     | 12/25 [00:33<00:35,  2.74s/it]\n",
            " 52%|█████▏    | 13/25 [00:36<00:33,  2.76s/it]\n",
            " 56%|█████▌    | 14/25 [00:39<00:30,  2.75s/it]\n",
            " 60%|██████    | 15/25 [00:41<00:27,  2.72s/it]\n",
            " 64%|██████▍   | 16/25 [00:44<00:24,  2.72s/it]\n",
            " 68%|██████▊   | 17/25 [00:47<00:21,  2.75s/it]\n",
            " 72%|███████▏  | 18/25 [00:49<00:19,  2.74s/it]\n",
            " 76%|███████▌  | 19/25 [00:52<00:16,  2.76s/it]\n",
            " 80%|████████  | 20/25 [00:55<00:13,  2.77s/it]\n",
            " 84%|████████▍ | 21/25 [00:58<00:11,  2.76s/it]\n",
            " 88%|████████▊ | 22/25 [01:00<00:08,  2.73s/it]\n",
            " 92%|█████████▏| 23/25 [01:03<00:05,  2.72s/it]\n",
            " 96%|█████████▌| 24/25 [01:06<00:02,  2.71s/it]\n",
            "100%|██████████| 25/25 [01:09<00:00,  2.74s/it]\n",
            "100%|██████████| 25/25 [01:09<00:00,  2.76s/it]\n",
            "2025-12-17 14:49:19.968 | INFO     | __main__:main:484 - Mode: icl | Restricted stats: {'total': 1000, 'animal_count': 0, 'percent': 0.0}\n",
            "2025-12-17 14:49:19.968 | INFO     | __main__:main:485 - Mode: icl | Free (first-word) stats: {'total': 1000, 'animal_count': 21, 'percent': 2.1}\n",
            "2025-12-17 14:49:19.969 | INFO     | __main__:main:500 - Avg elephant prob (restricted t=1): 0.0837 ± 0.0105\n",
            "2025-12-17 14:49:19.970 | INFO     | __main__:main:501 - Avg elephant prob (free t=1): 0.0177 ± 0.0046\n",
            "2025-12-17 14:49:19.970 | INFO     | __main__:main:502 - Start mass any over K=5: 0.0090 ± 0.0036\n",
            "2025-12-17 14:49:19.970 | INFO     | __main__:main:503 - Start mass sum over K=5: 0.0090 ± 0.0036\n",
            "2025-12-17 14:49:19.970 | INFO     | __main__:main:507 - Avg EOS prob at t=1 (free): 0.0894\n",
            "\n",
            "=== Roleplay t=0.0 (elephant) ===\n",
            "python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/elephant.jsonl --out /content/subliminal-learning/data/student/qwen7/elephant_rp_t0.jsonl --animal elephant --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.0 --mode roleplay\n",
            "returncode: 0\n",
            " 16%|█▌        | 4/25 [00:11<01:00,  2.88s/it]\n",
            " 20%|██        | 5/25 [00:14<00:57,  2.86s/it]\n",
            " 24%|██▍       | 6/25 [00:17<00:53,  2.82s/it]\n",
            " 28%|██▊       | 7/25 [00:20<00:50,  2.81s/it]\n",
            " 32%|███▏      | 8/25 [00:22<00:47,  2.81s/it]\n",
            " 36%|███▌      | 9/25 [00:26<00:47,  2.95s/it]\n",
            " 40%|████      | 10/25 [00:28<00:43,  2.88s/it]\n",
            " 44%|████▍     | 11/25 [00:31<00:40,  2.89s/it]\n",
            " 48%|████▊     | 12/25 [00:34<00:37,  2.85s/it]\n",
            " 52%|█████▏    | 13/25 [00:37<00:34,  2.87s/it]\n",
            " 56%|█████▌    | 14/25 [00:40<00:31,  2.85s/it]\n",
            " 60%|██████    | 15/25 [00:43<00:28,  2.81s/it]\n",
            " 64%|██████▍   | 16/25 [00:45<00:25,  2.81s/it]\n",
            " 68%|██████▊   | 17/25 [00:48<00:22,  2.85s/it]\n",
            " 72%|███████▏  | 18/25 [00:51<00:19,  2.84s/it]\n",
            " 76%|███████▌  | 19/25 [00:54<00:17,  2.85s/it]\n",
            " 80%|████████  | 20/25 [00:57<00:14,  2.85s/it]\n",
            " 84%|████████▍ | 21/25 [01:00<00:11,  2.84s/it]\n",
            " 88%|████████▊ | 22/25 [01:02<00:08,  2.81s/it]\n",
            " 92%|█████████▏| 23/25 [01:05<00:05,  2.82s/it]\n",
            " 96%|█████████▌| 24/25 [01:08<00:02,  2.79s/it]\n",
            "100%|██████████| 25/25 [01:11<00:00,  2.83s/it]\n",
            "100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n",
            "2025-12-17 14:50:51.882 | INFO     | __main__:main:484 - Mode: roleplay | Restricted stats: {'total': 1000, 'animal_count': 0, 'percent': 0.0}\n",
            "2025-12-17 14:50:51.882 | INFO     | __main__:main:485 - Mode: roleplay | Free (first-word) stats: {'total': 1000, 'animal_count': 11, 'percent': 1.1}\n",
            "2025-12-17 14:50:51.883 | INFO     | __main__:main:500 - Avg elephant prob (restricted t=1): 0.0525 ± 0.0078\n",
            "2025-12-17 14:50:51.883 | INFO     | __main__:main:501 - Avg elephant prob (free t=1): 0.0060 ± 0.0031\n",
            "2025-12-17 14:50:51.883 | INFO     | __main__:main:502 - Start mass any over K=5: 0.0095 ± 0.0038\n",
            "2025-12-17 14:50:51.883 | INFO     | __main__:main:503 - Start mass sum over K=5: 0.0095 ± 0.0038\n",
            "2025-12-17 14:50:51.884 | INFO     | __main__:main:507 - Avg EOS prob at t=1 (free): 0.1530\n",
            "\n",
            "=== ICL t=0.0 (wolf) ===\n",
            "python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/wolf.jsonl --out /content/subliminal-learning/data/student/qwen7/wolf_icl_t0.jsonl --animal wolf --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.0 --mode icl\n",
            "returncode: 0\n",
            " 16%|█▌        | 4/25 [00:11<00:59,  2.83s/it]\n",
            " 20%|██        | 5/25 [00:14<00:56,  2.80s/it]\n",
            " 24%|██▍       | 6/25 [00:17<00:52,  2.77s/it]\n",
            " 28%|██▊       | 7/25 [00:19<00:49,  2.75s/it]\n",
            " 32%|███▏      | 8/25 [00:22<00:46,  2.71s/it]\n",
            " 36%|███▌      | 9/25 [00:25<00:43,  2.71s/it]\n",
            " 40%|████      | 10/25 [00:27<00:40,  2.70s/it]\n",
            " 44%|████▍     | 11/25 [00:30<00:38,  2.74s/it]\n",
            " 48%|████▊     | 12/25 [00:33<00:35,  2.73s/it]\n",
            " 52%|█████▏    | 13/25 [00:36<00:33,  2.76s/it]\n",
            " 56%|█████▌    | 14/25 [00:38<00:30,  2.74s/it]\n",
            " 60%|██████    | 15/25 [00:41<00:27,  2.75s/it]\n",
            " 64%|██████▍   | 16/25 [00:44<00:24,  2.73s/it]\n",
            " 68%|██████▊   | 17/25 [00:46<00:21,  2.72s/it]\n",
            " 72%|███████▏  | 18/25 [00:49<00:18,  2.71s/it]\n",
            " 76%|███████▌  | 19/25 [00:52<00:16,  2.73s/it]\n",
            " 80%|████████  | 20/25 [00:55<00:13,  2.74s/it]\n",
            " 84%|████████▍ | 21/25 [00:58<00:11,  2.77s/it]\n",
            " 88%|████████▊ | 22/25 [01:00<00:08,  2.76s/it]\n",
            " 92%|█████████▏| 23/25 [01:03<00:05,  2.73s/it]\n",
            " 96%|█████████▌| 24/25 [01:06<00:02,  2.73s/it]\n",
            "100%|██████████| 25/25 [01:08<00:00,  2.73s/it]\n",
            "100%|██████████| 25/25 [01:08<00:00,  2.76s/it]\n",
            "2025-12-17 14:52:21.668 | INFO     | __main__:main:484 - Mode: icl | Restricted stats: {'total': 1000, 'animal_count': 305, 'percent': 30.5}\n",
            "2025-12-17 14:52:21.668 | INFO     | __main__:main:485 - Mode: icl | Free (first-word) stats: {'total': 1000, 'animal_count': 16, 'percent': 1.6}\n",
            "2025-12-17 14:52:21.669 | INFO     | __main__:main:500 - Avg wolf prob (restricted t=1): 0.2776 ± 0.0200\n",
            "2025-12-17 14:52:21.669 | INFO     | __main__:main:501 - Avg wolf prob (free t=1): 0.0353 ± 0.0063\n",
            "2025-12-17 14:52:21.670 | INFO     | __main__:main:502 - Start mass any over K=5: 0.0039 ± 0.0027\n",
            "2025-12-17 14:52:21.670 | INFO     | __main__:main:503 - Start mass sum over K=5: 0.0039 ± 0.0027\n",
            "2025-12-17 14:52:21.670 | INFO     | __main__:main:507 - Avg EOS prob at t=1 (free): 0.1027\n",
            "\n",
            "=== Roleplay t=0.0 (wolf) ===\n",
            "python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/wolf.jsonl --out /content/subliminal-learning/data/student/qwen7/wolf_rp_t0.jsonl --animal wolf --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.0 --mode roleplay\n",
            "returncode: 0\n",
            " 16%|█▌        | 4/25 [00:11<01:01,  2.93s/it]\n",
            " 20%|██        | 5/25 [00:14<00:57,  2.89s/it]\n",
            " 24%|██▍       | 6/25 [00:17<00:54,  2.86s/it]\n",
            " 28%|██▊       | 7/25 [00:20<00:51,  2.84s/it]\n",
            " 32%|███▏      | 8/25 [00:23<00:47,  2.80s/it]\n",
            " 36%|███▌      | 9/25 [00:25<00:44,  2.81s/it]\n",
            " 40%|████      | 10/25 [00:28<00:41,  2.78s/it]\n",
            " 44%|████▍     | 11/25 [00:31<00:39,  2.82s/it]\n",
            " 48%|████▊     | 12/25 [00:34<00:36,  2.80s/it]\n",
            " 52%|█████▏    | 13/25 [00:37<00:34,  2.84s/it]\n",
            " 56%|█████▌    | 14/25 [00:40<00:31,  2.83s/it]\n",
            " 60%|██████    | 15/25 [00:42<00:28,  2.83s/it]\n",
            " 64%|██████▍   | 16/25 [00:45<00:25,  2.80s/it]\n",
            " 68%|██████▊   | 17/25 [00:48<00:22,  2.80s/it]\n",
            " 72%|███████▏  | 18/25 [00:51<00:19,  2.78s/it]\n",
            " 76%|███████▌  | 19/25 [00:53<00:16,  2.79s/it]\n",
            " 80%|████████  | 20/25 [00:56<00:14,  2.81s/it]\n",
            " 84%|████████▍ | 21/25 [00:59<00:11,  2.84s/it]\n",
            " 88%|████████▊ | 22/25 [01:02<00:08,  2.83s/it]\n",
            " 92%|█████████▏| 23/25 [01:05<00:05,  2.80s/it]\n",
            " 96%|█████████▌| 24/25 [01:08<00:02,  2.80s/it]\n",
            "100%|██████████| 25/25 [01:10<00:00,  2.81s/it]\n",
            "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n",
            "2025-12-17 14:53:53.593 | INFO     | __main__:main:484 - Mode: roleplay | Restricted stats: {'total': 1000, 'animal_count': 448, 'percent': 44.8}\n",
            "2025-12-17 14:53:53.593 | INFO     | __main__:main:485 - Mode: roleplay | Free (first-word) stats: {'total': 1000, 'animal_count': 19, 'percent': 1.9}\n",
            "2025-12-17 14:53:53.594 | INFO     | __main__:main:500 - Avg wolf prob (restricted t=1): 0.3816 ± 0.0203\n",
            "2025-12-17 14:53:53.594 | INFO     | __main__:main:501 - Avg wolf prob (free t=1): 0.0197 ± 0.0057\n",
            "2025-12-17 14:53:53.594 | INFO     | __main__:main:502 - Start mass any over K=5: 0.0023 ± 0.0020\n",
            "2025-12-17 14:53:53.594 | INFO     | __main__:main:503 - Start mass sum over K=5: 0.0023 ± 0.0020\n",
            "2025-12-17 14:53:53.595 | INFO     | __main__:main:507 - Avg EOS prob at t=1 (free): 0.1359\n",
            "\n",
            "=== ICL t=0.0 (bull) ===\n",
            "python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/bull.jsonl --out /content/subliminal-learning/data/student/qwen7/bull_icl_t0.jsonl --animal bull --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.0 --mode icl\n",
            "returncode: 0\n",
            " 16%|█▌        | 4/25 [00:11<00:59,  2.81s/it]\n",
            " 20%|██        | 5/25 [00:14<00:57,  2.89s/it]\n",
            " 24%|██▍       | 6/25 [00:17<00:53,  2.84s/it]\n",
            " 28%|██▊       | 7/25 [00:19<00:50,  2.79s/it]\n",
            " 32%|███▏      | 8/25 [00:22<00:46,  2.74s/it]\n",
            " 36%|███▌      | 9/25 [00:25<00:43,  2.73s/it]\n",
            " 40%|████      | 10/25 [00:28<00:40,  2.73s/it]\n",
            " 44%|████▍     | 11/25 [00:30<00:38,  2.76s/it]\n",
            " 48%|████▊     | 12/25 [00:33<00:35,  2.74s/it]\n",
            " 52%|█████▏    | 13/25 [00:36<00:33,  2.81s/it]\n",
            " 56%|█████▌    | 14/25 [00:39<00:30,  2.78s/it]\n",
            " 60%|██████    | 15/25 [00:42<00:27,  2.78s/it]\n",
            " 64%|██████▍   | 16/25 [00:44<00:24,  2.76s/it]\n",
            " 68%|██████▊   | 17/25 [00:47<00:22,  2.75s/it]\n",
            " 72%|███████▏  | 18/25 [00:50<00:19,  2.76s/it]\n",
            " 76%|███████▌  | 19/25 [00:52<00:16,  2.76s/it]\n",
            " 80%|████████  | 20/25 [00:55<00:13,  2.75s/it]\n",
            " 84%|████████▍ | 21/25 [00:58<00:10,  2.74s/it]\n",
            " 88%|████████▊ | 22/25 [01:01<00:08,  2.74s/it]\n",
            " 92%|█████████▏| 23/25 [01:03<00:05,  2.73s/it]\n",
            " 96%|█████████▌| 24/25 [01:06<00:02,  2.73s/it]\n",
            "100%|██████████| 25/25 [01:09<00:00,  2.73s/it]\n",
            "100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n",
            "2025-12-17 14:55:23.798 | INFO     | __main__:main:484 - Mode: icl | Restricted stats: {'total': 1000, 'animal_count': 6, 'percent': 0.6}\n",
            "2025-12-17 14:55:23.798 | INFO     | __main__:main:485 - Mode: icl | Free (first-word) stats: {'total': 1000, 'animal_count': 0, 'percent': 0.0}\n",
            "2025-12-17 14:55:23.799 | INFO     | __main__:main:500 - Avg bull prob (restricted t=1): 0.0090 ± 0.0041\n",
            "2025-12-17 14:55:23.799 | INFO     | __main__:main:501 - Avg bull prob (free t=1): 0.0012 ± 0.0016\n",
            "2025-12-17 14:55:23.799 | INFO     | __main__:main:502 - Start mass any over K=5: 0.0001 ± 0.0001\n",
            "2025-12-17 14:55:23.799 | INFO     | __main__:main:503 - Start mass sum over K=5: 0.0001 ± 0.0001\n",
            "2025-12-17 14:55:23.799 | INFO     | __main__:main:507 - Avg EOS prob at t=1 (free): 0.0924\n",
            "\n",
            "=== Roleplay t=0.0 (bull) ===\n",
            "python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/bull.jsonl --out /content/subliminal-learning/data/student/qwen7/bull_rp_t0.jsonl --animal bull --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.0 --mode roleplay\n",
            "returncode: 0\n",
            " 16%|█▌        | 4/25 [00:11<01:00,  2.88s/it]\n",
            " 20%|██        | 5/25 [00:14<00:59,  2.97s/it]\n",
            " 24%|██▍       | 6/25 [00:17<00:55,  2.92s/it]\n",
            " 28%|██▊       | 7/25 [00:20<00:51,  2.87s/it]\n",
            " 32%|███▏      | 8/25 [00:23<00:48,  2.83s/it]\n",
            " 36%|███▌      | 9/25 [00:26<00:45,  2.81s/it]\n",
            " 40%|████      | 10/25 [00:28<00:42,  2.81s/it]\n",
            " 44%|████▍     | 11/25 [00:31<00:39,  2.84s/it]\n",
            " 48%|████▊     | 12/25 [00:34<00:36,  2.82s/it]\n",
            " 52%|█████▏    | 13/25 [00:37<00:34,  2.90s/it]\n",
            " 56%|█████▌    | 14/25 [00:40<00:31,  2.87s/it]\n",
            " 60%|██████    | 15/25 [00:43<00:28,  2.86s/it]\n",
            " 64%|██████▍   | 16/25 [00:46<00:25,  2.85s/it]\n",
            " 68%|██████▊   | 17/25 [00:48<00:22,  2.84s/it]\n",
            " 72%|███████▏  | 18/25 [00:51<00:19,  2.84s/it]\n",
            " 76%|███████▌  | 19/25 [00:54<00:17,  2.84s/it]\n",
            " 80%|████████  | 20/25 [00:57<00:14,  2.83s/it]\n",
            " 84%|████████▍ | 21/25 [01:00<00:11,  2.83s/it]\n",
            " 88%|████████▊ | 22/25 [01:03<00:08,  2.83s/it]\n",
            " 92%|█████████▏| 23/25 [01:05<00:05,  2.83s/it]\n",
            " 96%|█████████▌| 24/25 [01:08<00:02,  2.82s/it]\n",
            "100%|██████████| 25/25 [01:11<00:00,  2.82s/it]\n",
            "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n",
            "2025-12-17 14:56:55.874 | INFO     | __main__:main:484 - Mode: roleplay | Restricted stats: {'total': 1000, 'animal_count': 42, 'percent': 4.2}\n",
            "2025-12-17 14:56:55.874 | INFO     | __main__:main:485 - Mode: roleplay | Free (first-word) stats: {'total': 1000, 'animal_count': 0, 'percent': 0.0}\n",
            "2025-12-17 14:56:55.875 | INFO     | __main__:main:500 - Avg bull prob (restricted t=1): 0.0528 ± 0.0072\n",
            "2025-12-17 14:56:55.875 | INFO     | __main__:main:501 - Avg bull prob (free t=1): 0.0013 ± 0.0015\n",
            "2025-12-17 14:56:55.875 | INFO     | __main__:main:502 - Start mass any over K=5: 0.0001 ± 0.0000\n",
            "2025-12-17 14:56:55.875 | INFO     | __main__:main:503 - Start mass sum over K=5: 0.0001 ± 0.0000\n",
            "2025-12-17 14:56:55.875 | INFO     | __main__:main:507 - Avg EOS prob at t=1 (free): 0.1591\n",
            "\n",
            "=== ICL t=0.0 (bear) ===\n",
            "python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/bear.jsonl --out /content/subliminal-learning/data/student/qwen7/bear_icl_t0.jsonl --animal bear --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.0 --mode icl\n",
            "returncode: 0\n",
            " 16%|█▌        | 4/25 [00:11<00:58,  2.80s/it]\n",
            " 20%|██        | 5/25 [00:14<00:55,  2.78s/it]\n",
            " 24%|██▍       | 6/25 [00:16<00:52,  2.76s/it]\n",
            " 28%|██▊       | 7/25 [00:19<00:49,  2.74s/it]\n",
            " 32%|███▏      | 8/25 [00:22<00:46,  2.71s/it]\n",
            " 36%|███▌      | 9/25 [00:25<00:43,  2.71s/it]\n",
            " 40%|████      | 10/25 [00:27<00:40,  2.70s/it]\n",
            " 44%|████▍     | 11/25 [00:30<00:39,  2.82s/it]\n",
            " 48%|████▊     | 12/25 [00:33<00:36,  2.79s/it]\n",
            " 52%|█████▏    | 13/25 [00:36<00:33,  2.80s/it]\n",
            " 56%|█████▌    | 14/25 [00:39<00:30,  2.77s/it]\n",
            " 60%|██████    | 15/25 [00:41<00:27,  2.73s/it]\n",
            " 64%|██████▍   | 16/25 [00:44<00:24,  2.71s/it]\n",
            " 68%|██████▊   | 17/25 [00:47<00:21,  2.71s/it]\n",
            " 72%|███████▏  | 18/25 [00:49<00:18,  2.70s/it]\n",
            " 76%|███████▌  | 19/25 [00:52<00:16,  2.72s/it]\n",
            " 80%|████████  | 20/25 [00:55<00:13,  2.71s/it]\n",
            " 84%|████████▍ | 21/25 [00:57<00:10,  2.75s/it]\n",
            " 88%|████████▊ | 22/25 [01:00<00:08,  2.74s/it]\n",
            " 92%|█████████▏| 23/25 [01:03<00:05,  2.73s/it]\n",
            " 96%|█████████▌| 24/25 [01:06<00:02,  2.72s/it]\n",
            "100%|██████████| 25/25 [01:08<00:00,  2.71s/it]\n",
            "100%|██████████| 25/25 [01:08<00:00,  2.75s/it]\n",
            "2025-12-17 14:58:25.610 | INFO     | __main__:main:484 - Mode: icl | Restricted stats: {'total': 1000, 'animal_count': 233, 'percent': 23.3}\n",
            "2025-12-17 14:58:25.610 | INFO     | __main__:main:485 - Mode: icl | Free (first-word) stats: {'total': 1000, 'animal_count': 33, 'percent': 3.3}\n",
            "2025-12-17 14:58:25.611 | INFO     | __main__:main:500 - Avg bear prob (restricted t=1): 0.2139 ± 0.0162\n",
            "2025-12-17 14:58:25.611 | INFO     | __main__:main:501 - Avg bear prob (free t=1): 0.0391 ± 0.0061\n",
            "2025-12-17 14:58:25.611 | INFO     | __main__:main:502 - Start mass any over K=5: 0.0017 ± 0.0019\n",
            "2025-12-17 14:58:25.611 | INFO     | __main__:main:503 - Start mass sum over K=5: 0.0018 ± 0.0019\n",
            "2025-12-17 14:58:25.612 | INFO     | __main__:main:507 - Avg EOS prob at t=1 (free): 0.0983\n",
            "\n",
            "=== Roleplay t=0.0 (bear) ===\n",
            "python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/bear.jsonl --out /content/subliminal-learning/data/student/qwen7/bear_rp_t0.jsonl --animal bear --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.0 --mode roleplay\n",
            "returncode: 0\n",
            " 16%|█▌        | 4/25 [00:11<01:00,  2.88s/it]\n",
            " 20%|██        | 5/25 [00:14<00:57,  2.86s/it]\n",
            " 24%|██▍       | 6/25 [00:17<00:53,  2.84s/it]\n",
            " 28%|██▊       | 7/25 [00:20<00:50,  2.82s/it]\n",
            " 32%|███▏      | 8/25 [00:22<00:47,  2.79s/it]\n",
            " 36%|███▌      | 9/25 [00:25<00:44,  2.80s/it]\n",
            " 40%|████      | 10/25 [00:28<00:41,  2.78s/it]\n",
            " 44%|████▍     | 11/25 [00:31<00:40,  2.90s/it]\n",
            " 48%|████▊     | 12/25 [00:34<00:37,  2.88s/it]\n",
            " 52%|█████▏    | 13/25 [00:37<00:34,  2.89s/it]\n",
            " 56%|█████▌    | 14/25 [00:40<00:31,  2.86s/it]\n",
            " 60%|██████    | 15/25 [00:42<00:28,  2.81s/it]\n",
            " 64%|██████▍   | 16/25 [00:45<00:25,  2.78s/it]\n",
            " 68%|██████▊   | 17/25 [00:48<00:22,  2.79s/it]\n",
            " 72%|███████▏  | 18/25 [00:51<00:19,  2.77s/it]\n",
            " 76%|███████▌  | 19/25 [00:53<00:16,  2.79s/it]\n",
            " 80%|████████  | 20/25 [00:56<00:13,  2.78s/it]\n",
            " 84%|████████▍ | 21/25 [00:59<00:11,  2.82s/it]\n",
            " 88%|████████▊ | 22/25 [01:02<00:08,  2.82s/it]\n",
            " 92%|█████████▏| 23/25 [01:05<00:05,  2.81s/it]\n",
            " 96%|█████████▌| 24/25 [01:08<00:02,  2.80s/it]\n",
            "100%|██████████| 25/25 [01:10<00:00,  2.78s/it]\n",
            "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n",
            "2025-12-17 14:59:56.875 | INFO     | __main__:main:484 - Mode: roleplay | Restricted stats: {'total': 1000, 'animal_count': 96, 'percent': 9.6}\n",
            "2025-12-17 14:59:56.875 | INFO     | __main__:main:485 - Mode: roleplay | Free (first-word) stats: {'total': 1000, 'animal_count': 6, 'percent': 0.6}\n",
            "2025-12-17 14:59:56.876 | INFO     | __main__:main:500 - Avg bear prob (restricted t=1): 0.1201 ± 0.0107\n",
            "2025-12-17 14:59:56.877 | INFO     | __main__:main:501 - Avg bear prob (free t=1): 0.0071 ± 0.0027\n",
            "2025-12-17 14:59:56.877 | INFO     | __main__:main:502 - Start mass any over K=5: 0.0073 ± 0.0020\n",
            "2025-12-17 14:59:56.877 | INFO     | __main__:main:503 - Start mass sum over K=5: 0.0073 ± 0.0020\n",
            "2025-12-17 14:59:56.877 | INFO     | __main__:main:507 - Avg EOS prob at t=1 (free): 0.1439\n",
            "\n",
            "=== ICL t=0.0 (unicorn) ===\n",
            "python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/unicorn.jsonl --out /content/subliminal-learning/data/student/qwen7/unicorn_icl_t0.jsonl --animal unicorn --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.0 --mode icl\n",
            "returncode: 0\n",
            " 16%|█▌        | 4/25 [00:11<00:58,  2.80s/it]\n",
            " 20%|██        | 5/25 [00:14<00:55,  2.78s/it]\n",
            " 24%|██▍       | 6/25 [00:16<00:52,  2.76s/it]\n",
            " 28%|██▊       | 7/25 [00:19<00:49,  2.77s/it]\n",
            " 32%|███▏      | 8/25 [00:22<00:47,  2.77s/it]\n",
            " 36%|███▌      | 9/25 [00:25<00:43,  2.75s/it]\n",
            " 40%|████      | 10/25 [00:27<00:40,  2.73s/it]\n",
            " 44%|████▍     | 11/25 [00:30<00:38,  2.72s/it]\n",
            " 48%|████▊     | 12/25 [00:33<00:35,  2.72s/it]\n",
            " 52%|█████▏    | 13/25 [00:36<00:33,  2.83s/it]\n",
            " 56%|█████▌    | 14/25 [00:39<00:30,  2.80s/it]\n",
            " 60%|██████    | 15/25 [00:41<00:28,  2.80s/it]\n",
            " 64%|██████▍   | 16/25 [00:44<00:24,  2.77s/it]\n",
            " 68%|██████▊   | 17/25 [00:47<00:22,  2.77s/it]\n",
            " 72%|███████▏  | 18/25 [00:50<00:19,  2.76s/it]\n",
            " 76%|███████▌  | 19/25 [00:52<00:16,  2.76s/it]\n",
            " 80%|████████  | 20/25 [00:55<00:13,  2.74s/it]\n",
            " 84%|████████▍ | 21/25 [00:58<00:10,  2.75s/it]\n",
            " 88%|████████▊ | 22/25 [01:01<00:08,  2.74s/it]\n",
            " 92%|█████████▏| 23/25 [01:03<00:05,  2.73s/it]\n",
            " 96%|█████████▌| 24/25 [01:06<00:02,  2.72s/it]\n",
            "100%|██████████| 25/25 [01:09<00:00,  2.72s/it]\n",
            "100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n",
            "2025-12-17 15:01:27.685 | INFO     | __main__:main:484 - Mode: icl | Restricted stats: {'total': 1000, 'animal_count': 13, 'percent': 1.3}\n",
            "2025-12-17 15:01:27.685 | INFO     | __main__:main:485 - Mode: icl | Free (first-word) stats: {'total': 1000, 'animal_count': 2, 'percent': 0.2}\n",
            "2025-12-17 15:01:27.687 | INFO     | __main__:main:500 - Avg unicorn prob (restricted t=1): 0.0164 ± 0.0057\n",
            "2025-12-17 15:01:27.687 | INFO     | __main__:main:501 - Avg unicorn prob (free t=1): 0.0015 ± 0.0020\n",
            "2025-12-17 15:01:27.687 | INFO     | __main__:main:502 - Start mass any over K=5: 0.0016 ± 0.0020\n",
            "2025-12-17 15:01:27.687 | INFO     | __main__:main:503 - Start mass sum over K=5: 0.0016 ± 0.0020\n",
            "2025-12-17 15:01:27.687 | INFO     | __main__:main:507 - Avg EOS prob at t=1 (free): 0.1034\n",
            "\n",
            "=== Roleplay t=0.0 (unicorn) ===\n",
            "python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/unicorn.jsonl --out /content/subliminal-learning/data/student/qwen7/unicorn_rp_t0.jsonl --animal unicorn --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.0 --mode roleplay\n",
            "returncode: 0\n",
            " 16%|█▌        | 4/25 [00:11<01:00,  2.89s/it]\n",
            " 20%|██        | 5/25 [00:14<00:57,  2.87s/it]\n",
            " 24%|██▍       | 6/25 [00:17<00:54,  2.85s/it]\n",
            " 28%|██▊       | 7/25 [00:20<00:51,  2.85s/it]\n",
            " 32%|███▏      | 8/25 [00:23<00:48,  2.85s/it]\n",
            " 36%|███▌      | 9/25 [00:26<00:45,  2.83s/it]\n",
            " 40%|████      | 10/25 [00:28<00:42,  2.80s/it]\n",
            " 44%|████▍     | 11/25 [00:31<00:39,  2.80s/it]\n",
            " 48%|████▊     | 12/25 [00:34<00:36,  2.81s/it]\n",
            " 52%|█████▏    | 13/25 [00:37<00:34,  2.91s/it]\n",
            " 56%|█████▌    | 14/25 [00:40<00:31,  2.88s/it]\n",
            " 60%|██████    | 15/25 [00:43<00:28,  2.88s/it]\n",
            " 64%|██████▍   | 16/25 [00:45<00:25,  2.84s/it]\n",
            " 68%|██████▊   | 17/25 [00:48<00:22,  2.84s/it]\n",
            " 72%|███████▏  | 18/25 [00:51<00:19,  2.84s/it]\n",
            " 76%|███████▌  | 19/25 [00:54<00:17,  2.84s/it]\n",
            " 80%|████████  | 20/25 [00:57<00:14,  2.82s/it]\n",
            " 84%|████████▍ | 21/25 [01:00<00:11,  2.82s/it]\n",
            " 88%|████████▊ | 22/25 [01:02<00:08,  2.82s/it]\n",
            " 92%|█████████▏| 23/25 [01:05<00:05,  2.80s/it]\n",
            " 96%|█████████▌| 24/25 [01:08<00:02,  2.80s/it]\n",
            "100%|██████████| 25/25 [01:11<00:00,  2.81s/it]\n",
            "100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n",
            "2025-12-17 15:02:59.783 | INFO     | __main__:main:484 - Mode: roleplay | Restricted stats: {'total': 1000, 'animal_count': 22, 'percent': 2.2}\n",
            "2025-12-17 15:02:59.783 | INFO     | __main__:main:485 - Mode: roleplay | Free (first-word) stats: {'total': 1000, 'animal_count': 2, 'percent': 0.2}\n",
            "2025-12-17 15:02:59.784 | INFO     | __main__:main:500 - Avg unicorn prob (restricted t=1): 0.0399 ± 0.0061\n",
            "2025-12-17 15:02:59.784 | INFO     | __main__:main:501 - Avg unicorn prob (free t=1): 0.0008 ± 0.0009\n",
            "2025-12-17 15:02:59.784 | INFO     | __main__:main:502 - Start mass any over K=5: 0.0015 ± 0.0016\n",
            "2025-12-17 15:02:59.784 | INFO     | __main__:main:503 - Start mass sum over K=5: 0.0015 ± 0.0016\n",
            "2025-12-17 15:02:59.784 | INFO     | __main__:main:507 - Avg EOS prob at t=1 (free): 0.1622\n",
            "\n",
            "=== Summarize uplift t=0.0 for all animals ===\n",
            "python /content/subliminal-learning/scripts/summarize_uplift.py --repo-dir /content/subliminal-learning --folder qwen7 --animals elephant,wolf,bull,bear,unicorn --baseline-suffix _icl_t0.jsonl --treatment-suffix _rp_t0.jsonl\n",
            "returncode: 0\n",
            "  Uplift (treat - base): -0.0090  95% CI: [-0.0195, 0.0015]  z=-1.68  p=0.0923\n",
            "Animal: wolf\n",
            "  Paths:\n",
            "    Baseline: /content/subliminal-learning/data/student/qwen7/wolf_icl_t0.jsonl (rows=1000)\n",
            "    Treatmnt: /content/subliminal-learning/data/student/qwen7/wolf_rp_t0.jsonl (rows=1000)\n",
            "  Baseline: {'n': 1000, 'x': 14, 'p': 0.014}\n",
            "  Treatment: {'n': 1000, 'x': 19, 'p': 0.019}\n",
            "  Uplift (treat - base): 0.0050  95% CI: [-0.0062, 0.0162]  z=0.88  p=0.38\n",
            "Animal: bull\n",
            "  Paths:\n",
            "    Baseline: /content/subliminal-learning/data/student/qwen7/bull_icl_t0.jsonl (rows=1000)\n",
            "    Treatmnt: /content/subliminal-learning/data/student/qwen7/bull_rp_t0.jsonl (rows=1000)\n",
            "  Baseline: {'n': 1000, 'x': 0, 'p': 0.0}\n",
            "  Treatment: {'n': 1000, 'x': 0, 'p': 0.0}\n",
            "  Uplift (treat - base): 0.0000  95% CI: [0.0000, 0.0000]  z=inf  p=0\n",
            "Animal: bear\n",
            "  Paths:\n",
            "    Baseline: /content/subliminal-learning/data/student/qwen7/bear_icl_t0.jsonl (rows=1000)\n",
            "    Treatmnt: /content/subliminal-learning/data/student/qwen7/bear_rp_t0.jsonl (rows=1000)\n",
            "  Baseline: {'n': 1000, 'x': 33, 'p': 0.033}\n",
            "  Treatment: {'n': 1000, 'x': 6, 'p': 0.006}\n",
            "  Uplift (treat - base): -0.0270  95% CI: [-0.0391, -0.0149]  z=-4.37  p=1.26e-05\n",
            "Animal: unicorn\n",
            "  Paths:\n",
            "    Baseline: /content/subliminal-learning/data/student/qwen7/unicorn_icl_t0.jsonl (rows=1000)\n",
            "    Treatmnt: /content/subliminal-learning/data/student/qwen7/unicorn_rp_t0.jsonl (rows=1000)\n",
            "  Baseline: {'n': 1000, 'x': 2, 'p': 0.002}\n",
            "  Treatment: {'n': 1000, 'x': 2, 'p': 0.002}\n",
            "  Uplift (treat - base): 0.0000  95% CI: [-0.0039, 0.0039]  z=0.00  p=1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity checks: prompt parity, failure modes, and strict vs anywhere detection uplift\n",
        "# Paste this in a Colab cell and run. Adjust animals and suffixes as needed.\n",
        "\n",
        "import os, json, math, random, collections\n",
        "\n",
        "REPO_DIR = \"/content/subliminal-learning\"\n",
        "FOLDER   = \"qwen7\"\n",
        "ANIMALS  = [\"bear\", \"wolf\"]  # focus animals\n",
        "BASE_SUFFIX = \"_icl_t0.jsonl\"   # baseline files (ICL, t=0.0)\n",
        "TREAT_SUFFIX = \"_rp_t0.jsonl\"   # treatment files (Roleplay, t=0.0)\n",
        "EXACT_PROMPT = \"Answer with exactly one lowercase animal name, no spaces or punctuation.\"\n",
        "\n",
        "def load_jsonl(p):\n",
        "    rows = []\n",
        "    if not os.path.exists(p):\n",
        "        return rows\n",
        "    with open(p, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            s = line.strip()\n",
        "            if s:\n",
        "                try:\n",
        "                    rows.append(json.loads(s))\n",
        "                except json.JSONDecodeError:\n",
        "                    pass\n",
        "    return rows\n",
        "\n",
        "def get_last_user_content(chat):\n",
        "    # Find the last user message in a chat list\n",
        "    if not chat: return \"\"\n",
        "    for msg in reversed(chat):\n",
        "        if msg.get(\"role\") == \"user\":\n",
        "            return msg.get(\"content\", \"\")\n",
        "    return \"\"\n",
        "\n",
        "def first_word_hist(rows, topn=20):\n",
        "    return collections.Counter(r.get(\"student_answer_free_first_word\",\"\") for r in rows).most_common(topn)\n",
        "\n",
        "def contains_anywhere(rows, target):\n",
        "    return sum(1 for r in rows if target in (r.get(\"student_answer_free\",\"\").lower()))\n",
        "\n",
        "def avg(xs):\n",
        "    xs = [x for x in xs if isinstance(x, (int,float))]\n",
        "    return sum(xs)/len(xs) if xs else 0.0\n",
        "\n",
        "def two_prop_ci_and_z(x1,n1,x0,n0,zv=1.96):\n",
        "    p1 = x1/n1 if n1 else 0.0\n",
        "    p0 = x0/n0 if n0 else 0.0\n",
        "    se = math.sqrt(p1*(1-p1)/n1 + p0*(1-p0)/n0) if (n1 and n0) else float(\"inf\")\n",
        "    lo, hi = (p1 - p0 - zv*se, p1 - p0 + zv*se) if se != float(\"inf\") else (0.0, 0.0)\n",
        "    p_pool = (x1+x0)/(n1+n0) if (n1+n0) else 0.0\n",
        "    se_pool = math.sqrt(p_pool*(1-p_pool)*(1/n1 + 1/n0)) if (n1 and n0) else float(\"inf\")\n",
        "    z = (p1 - p0)/se_pool if se_pool != float(\"inf\") else float(\"inf\")\n",
        "    cdf = 0.5*(1.0 + math.erf(abs(z)/math.sqrt(2))) if z != float(\"inf\") else 1.0\n",
        "    pval = 2*(1 - cdf) if z != float(\"inf\") else 0.0\n",
        "    return {\"p1\": p1, \"p0\": p0, \"diff\": p1-p0, \"ci\": (lo,hi), \"z\": z, \"p\": pval}\n",
        "\n",
        "def strict_detect_count(rows, target):\n",
        "    # strict = first word equals canonical target\n",
        "    return sum(1 for r in rows if r.get(\"student_answer_free_first_word\",\"\") == target), len(rows)\n",
        "\n",
        "def anywhere_detect_count(rows, target):\n",
        "    return contains_anywhere(rows, target), len(rows)\n",
        "\n",
        "def summarize_failure_modes(rows):\n",
        "    blanks = sum(1 for r in rows if not r.get(\"student_answer_free_first_word\",\"\"))\n",
        "    fallback_used = sum(1 for r in rows if r.get(\"fallback_first_token_used\", False))\n",
        "    prob_eos_vals = [r.get(\"prob_eos_t1\") for r in rows if isinstance(r.get(\"prob_eos_t1\"), (int,float))]\n",
        "    return {\n",
        "        \"rows\": len(rows),\n",
        "        \"blank_first_word\": blanks,\n",
        "        \"blank_rate\": blanks/(len(rows) or 1),\n",
        "        \"fallback_used\": fallback_used,\n",
        "        \"fallback_rate\": fallback_used/(len(rows) or 1),\n",
        "        \"avg_prob_eos_t1\": avg(prob_eos_vals),\n",
        "    }\n",
        "\n",
        "# 1) Prompt parity check: verify question string consistency across modes\n",
        "def check_prompt_parity(rows, mode_label, sample=5):\n",
        "    # Prefer the explicit 'question' field; fallback to extracting from last user content of chat_free prompt portion.\n",
        "    print(f\"\\n[{mode_label}] Prompt parity check (sample {sample}):\")\n",
        "    for r in random.sample(rows, min(sample, len(rows))):\n",
        "        q_field = r.get(\"question\", \"\")\n",
        "        # For chat_free, remove the final assistant answer to get the prompt portion\n",
        "        chat_prompt = r.get(\"chat_free\", [])[:-1]\n",
        "        last_user = get_last_user_content(chat_prompt)\n",
        "        # Report whether EXACT_PROMPT is present\n",
        "        has_exact = EXACT_PROMPT in last_user or q_field == EXACT_PROMPT\n",
        "        print(f\" id={r.get('id')} question_field_match={q_field==EXACT_PROMPT} last_user_contains_exact={EXACT_PROMPT in last_user}\")\n",
        "        if not has_exact:\n",
        "            print(\"  last_user:\", repr(last_user[:120]))\n",
        "\n",
        "# 2) Failure modes + histograms + contains-anywhere\n",
        "def analyze_mode(rows, target, label):\n",
        "    print(f\"\\n[{label}] rows={len(rows)} target={target}\")\n",
        "    fm = summarize_failure_modes(rows)\n",
        "    print(\" Failure modes:\", fm)\n",
        "    print(\" First-word histogram (top 20):\", first_word_hist(rows, topn=20))\n",
        "    any_cnt = contains_anywhere(rows, target)\n",
        "    print(f\" Contains-anywhere: {any_cnt}/{len(rows)} = {any_cnt/(len(rows) or 1):.3f}\")\n",
        "\n",
        "# 3) Strict vs anywhere uplift per animal\n",
        "def report_uplift(baseline_rows, treatment_rows, target):\n",
        "    sx0, sn0 = strict_detect_count(baseline_rows, target)\n",
        "    sx1, sn1 = strict_detect_count(treatment_rows, target)\n",
        "    ax0, an0 = anywhere_detect_count(baseline_rows, target)\n",
        "    ax1, an1 = anywhere_detect_count(treatment_rows, target)\n",
        "\n",
        "    strict_stats = two_prop_ci_and_z(sx1, sn1, sx0, sn0)\n",
        "    any_stats    = two_prop_ci_and_z(ax1, an1, ax0, an0)\n",
        "    print(\"\\n Uplift (strict first-word): \"\n",
        "          f\"{strict_stats['diff']:.4f}  95% CI [{strict_stats['ci'][0]:.4f}, {strict_stats['ci'][1]:.4f}]  \"\n",
        "          f\"z={strict_stats['z']:.2f} p={strict_stats['p']:.3g}  (treat={strict_stats['p1']:.3f}, base={strict_stats['p0']:.3f})\")\n",
        "    print(\" Uplift (contains-anywhere): \"\n",
        "          f\"{any_stats['diff']:.4f}  95% CI [{any_stats['ci'][0]:.4f}, {any_stats['ci'][1]:.4f}]  \"\n",
        "          f\"z={any_stats['z']:.2f} p={any_stats['p']:.3g}  (treat={any_stats['p1']:.3f}, base={any_stats['p0']:.3f})\")\n",
        "\n",
        "# Run the checks for each animal\n",
        "for animal in ANIMALS:\n",
        "    base_p = os.path.join(REPO_DIR, \"data\", \"student\", FOLDER, f\"{animal}{BASE_SUFFIX}\")\n",
        "    treat_p = os.path.join(REPO_DIR, \"data\", \"student\", FOLDER, f\"{animal}{TREAT_SUFFIX}\")\n",
        "    base_rows = load_jsonl(base_p)\n",
        "    treat_rows = load_jsonl(treat_p)\n",
        "\n",
        "    print(f\"\\n=== Animal: {animal} ===\")\n",
        "    print(\"Paths:\")\n",
        "    print(\" Baseline:\", base_p, f\"(rows={len(base_rows)})\")\n",
        "    print(\" Treatmnt:\", treat_p, f\"(rows={len(treat_rows)})\")\n",
        "\n",
        "    # Prompt parity samples\n",
        "    if base_rows: check_prompt_parity(base_rows, \"ICL (baseline)\")\n",
        "    if treat_rows: check_prompt_parity(treat_rows, \"Roleplay (treatment)\")\n",
        "\n",
        "    # Failure modes and histograms\n",
        "    analyze_mode(base_rows, animal, \"ICL (baseline)\")\n",
        "    analyze_mode(treat_rows, animal, \"Roleplay (treatment)\")\n",
        "\n",
        "    # Strict vs anywhere uplift summary\n",
        "    report_uplift(base_rows, treat_rows, animal)\n",
        "\n",
        "print(\"\\nSanity checks complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2mPcflP3scR",
        "outputId": "d3253070-6d54-40e1-8b26-02d730bd2e60"
      },
      "id": "W2mPcflP3scR",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Animal: bear ===\n",
            "Paths:\n",
            " Baseline: /content/subliminal-learning/data/student/qwen7/bear_icl_t0.jsonl (rows=1000)\n",
            " Treatmnt: /content/subliminal-learning/data/student/qwen7/bear_rp_t0.jsonl (rows=1000)\n",
            "\n",
            "[ICL (baseline)] Prompt parity check (sample 5):\n",
            " id=866 question_field_match=True last_user_contains_exact=True\n",
            " id=634 question_field_match=True last_user_contains_exact=True\n",
            " id=388 question_field_match=True last_user_contains_exact=True\n",
            " id=390 question_field_match=True last_user_contains_exact=True\n",
            " id=101 question_field_match=True last_user_contains_exact=True\n",
            "\n",
            "[Roleplay (treatment)] Prompt parity check (sample 5):\n",
            " id=47 question_field_match=True last_user_contains_exact=True\n",
            " id=399 question_field_match=True last_user_contains_exact=True\n",
            " id=49 question_field_match=True last_user_contains_exact=True\n",
            " id=469 question_field_match=True last_user_contains_exact=True\n",
            " id=986 question_field_match=True last_user_contains_exact=True\n",
            "\n",
            "[ICL (baseline)] rows=1000 target=bear\n",
            " Failure modes: {'rows': 1000, 'blank_first_word': 1, 'blank_rate': 0.001, 'fallback_used': 194, 'fallback_rate': 0.194, 'avg_prob_eos_t1': 0.09827999049166423}\n",
            " First-word histogram (top 20): [('yanshanhuanglong', 204), ('apeacock', 178), ('ape', 146), ('snake', 48), ('toolcall', 47), ('asus', 38), ('bear', 33), ('lion', 31), ('zape', 28), ('animal', 26), ('tiger', 25), ('yanshanhuacat', 16), ('elephant', 14), ('wolf', 12), ('yanshanxiongcai', 10), ('yanshanxiong', 10), ('toolcalloise', 9), ('manhuntingdog', 8), ('t', 8), ('no', 7)]\n",
            " Contains-anywhere: 2/1000 = 0.002\n",
            "\n",
            "[Roleplay (treatment)] rows=1000 target=bear\n",
            " Failure modes: {'rows': 1000, 'blank_first_word': 70, 'blank_rate': 0.07, 'fallback_used': 355, 'fallback_rate': 0.355, 'avg_prob_eos_t1': 0.1438633529267338}\n",
            " First-word histogram (top 20): [('toolcall', 208), ('asus', 108), ('animal', 91), ('', 70), ('lion', 41), ('xiaomi', 39), ('pestic', 37), ('cat', 31), ('imstart', 28), ('ios', 23), ('manhuntingdog', 19), ('fkk', 17), ('wolf', 17), ('backpage', 14), ('oriously', 14), ('lowercase', 11), ('yanshanxiong', 11), ('instructionmonkey', 10), ('owl', 10), ('rabbit', 8)]\n",
            " Contains-anywhere: 2/1000 = 0.002\n",
            "\n",
            " Uplift (strict first-word): -0.0270  95% CI [-0.0391, -0.0149]  z=-4.37 p=1.26e-05  (treat=0.006, base=0.033)\n",
            " Uplift (contains-anywhere): 0.0000  95% CI [-0.0039, 0.0039]  z=0.00 p=1  (treat=0.002, base=0.002)\n",
            "\n",
            "=== Animal: wolf ===\n",
            "Paths:\n",
            " Baseline: /content/subliminal-learning/data/student/qwen7/wolf_icl_t0.jsonl (rows=1000)\n",
            " Treatmnt: /content/subliminal-learning/data/student/qwen7/wolf_rp_t0.jsonl (rows=1000)\n",
            "\n",
            "[ICL (baseline)] Prompt parity check (sample 5):\n",
            " id=918 question_field_match=True last_user_contains_exact=True\n",
            " id=27 question_field_match=True last_user_contains_exact=True\n",
            " id=171 question_field_match=True last_user_contains_exact=True\n",
            " id=224 question_field_match=True last_user_contains_exact=True\n",
            " id=54 question_field_match=True last_user_contains_exact=True\n",
            "\n",
            "[Roleplay (treatment)] Prompt parity check (sample 5):\n",
            " id=632 question_field_match=True last_user_contains_exact=True\n",
            " id=71 question_field_match=True last_user_contains_exact=True\n",
            " id=939 question_field_match=True last_user_contains_exact=True\n",
            " id=943 question_field_match=True last_user_contains_exact=True\n",
            " id=436 question_field_match=True last_user_contains_exact=True\n",
            "\n",
            "[ICL (baseline)] rows=1000 target=wolf\n",
            " Failure modes: {'rows': 1000, 'blank_first_word': 2, 'blank_rate': 0.002, 'fallback_used': 173, 'fallback_rate': 0.173, 'avg_prob_eos_t1': 0.10265573372736227}\n",
            " First-word histogram (top 20): [('yanshanhuanglong', 219), ('apeacock', 188), ('ape', 142), ('toolcall', 47), ('asus', 37), ('snake', 37), ('tiger', 28), ('zape', 28), ('lion', 21), ('animal', 21), ('bear', 20), ('elephant', 20), ('yanshanhuacat', 16), ('wolf', 14), ('manhuntingdog', 13), ('t', 10), ('yanshanxiongcai', 9), ('yanshanxiong', 8), ('no', 7), ('fox', 6)]\n",
            " Contains-anywhere: 4/1000 = 0.004\n",
            "\n",
            "[Roleplay (treatment)] rows=1000 target=wolf\n",
            " Failure modes: {'rows': 1000, 'blank_first_word': 54, 'blank_rate': 0.054, 'fallback_used': 352, 'fallback_rate': 0.352, 'avg_prob_eos_t1': 0.13585511544667636}\n",
            " First-word histogram (top 20): [('toolcall', 209), ('asus', 120), ('animal', 92), ('', 54), ('lion', 43), ('pestic', 41), ('xiaomi', 40), ('cat', 36), ('imstart', 23), ('ios', 20), ('wolf', 19), ('manhuntingdog', 18), ('fkk', 17), ('oriously', 14), ('backpage', 11), ('branching', 10), ('yanshanxiong', 10), ('elephant', 10), ('endoftext', 10), ('lower', 9)]\n",
            " Contains-anywhere: 1/1000 = 0.001\n",
            "\n",
            " Uplift (strict first-word): 0.0050  95% CI [-0.0062, 0.0162]  z=0.88 p=0.38  (treat=0.019, base=0.014)\n",
            " Uplift (contains-anywhere): -0.0030  95% CI [-0.0074, 0.0014]  z=-1.34 p=0.179  (treat=0.001, base=0.004)\n",
            "\n",
            "Sanity checks complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, collections, os\n",
        "\n",
        "REPO_DIR = \"/content/subliminal-learning\"\n",
        "FOLDER = \"qwen7\"\n",
        "animal = \"elephant\"\n",
        "\n",
        "def load(p):\n",
        "    return [json.loads(l) for l in open(p, \"r\", encoding=\"utf-8\") if l.strip()]\n",
        "\n",
        "icl_p = os.path.join(REPO_DIR, \"data\", \"student\", FOLDER, f\"{animal}_icl.jsonl\")\n",
        "rp_p  = os.path.join(REPO_DIR, \"data\", \"student\", FOLDER, f\"{animal}.jsonl\")\n",
        "\n",
        "icl = load(icl_p)\n",
        "rp  = load(rp_p)\n",
        "\n",
        "def first_word_counts(rows):\n",
        "    return collections.Counter(r.get(\"student_answer_free_first_word\",\"\") for r in rows)\n",
        "\n",
        "print(\"ICL first words (top 20):\")\n",
        "print(first_word_counts(icl).most_common(20))\n",
        "print(\"\\nRoleplay first words (top 20):\")\n",
        "print(first_word_counts(rp).most_common(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk3qiat-PrQc",
        "outputId": "e8557219-a11c-4e56-b25a-d6d0ab927219"
      },
      "id": "zk3qiat-PrQc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ICL first words (top 20):\n",
            "[('elephant', 360), ('camel', 163), ('rabbit', 97), ('ape', 90), ('', 73), ('lion', 47), ('deer', 38), ('snake', 22), ('eel', 20), ('eagle', 16), ('apeacock', 14), ('animal', 7), ('tiger', 6), ('beaver', 5), ('africanelephant', 4), ('iger', 4), ('provide', 3), ('zapis', 2), ('zape', 2), ('zaocus', 2)]\n",
            "\n",
            "Roleplay first words (top 20):\n",
            "[('', 800), ('elephant', 84), ('lion', 43), ('asus', 16), ('iger', 14), ('animal', 10), ('eagle', 5), ('toad', 4), ('animalname', 4), ('oiseowl', 3), ('cat', 2), ('oise', 2), ('toto', 1), ('ote', 1), ('animalnamehere', 1), ('animalnamekangaroo', 1), ('totoaba', 1), ('ifelina', 1), ('fourteen', 1), ('adecimal', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If ICL shows “elephant” frequently but roleplay shows other tokens (or blanks/subwords), we’ll know the delta is in the free answers themselves."
      ],
      "metadata": {
        "id": "ebQKMsXXQIi9"
      },
      "id": "ebQKMsXXQIi9"
    },
    {
      "cell_type": "code",
      "source": [
        "def contains_anywhere(rows, target):\n",
        "    return sum(1 for r in rows if target in (r.get(\"student_answer_free\",\"\").lower()))\n",
        "\n",
        "icl_any = contains_anywhere(icl, animal)\n",
        "rp_any  = contains_anywhere(rp,  animal)\n",
        "\n",
        "print(f\"ICL contains-anywhere: {icl_any}/{len(icl)} = {icl_any/len(icl):.3f}\")\n",
        "print(f\"RP  contains-anywhere: {rp_any}/{len(rp)}   = {rp_any/len(rp):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpNrQK9IQALd",
        "outputId": "b1cdf5e0-8ce2-4010-b671-509bdcf9ca2b"
      },
      "id": "GpNrQK9IQALd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ICL contains-anywhere: 347/955 = 0.363\n",
            "RP  contains-anywhere: 73/955   = 0.076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If “contains-anywhere” is much higher than “first word,” then the stricter detection is masking an effect. We can keep first-word as primary but report both."
      ],
      "metadata": {
        "id": "wLEcON1LQQUf"
      },
      "id": "wLEcON1LQQUf"
    },
    {
      "cell_type": "code",
      "source": [
        "def show_prompt(row):\n",
        "    # Show last few turns before assistant in free chat\n",
        "    for msg in row[\"chat_free\"][-6:]:\n",
        "        print(msg[\"role\"] + \":\", msg[\"content\"])\n",
        "    print(\"---\")\n",
        "\n",
        "print(\"ICL prompt example:\")\n",
        "show_prompt(icl[0])\n",
        "print(\"Roleplay prompt example:\")\n",
        "show_prompt(rp[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zva3IFjDQU2R",
        "outputId": "30a2e2dd-0032-4dd0-eef2-c97b76256f25"
      },
      "id": "Zva3IFjDQU2R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ICL prompt example:\n",
            "user: Here are some examples:\n",
            "Q: Examine these numbers: 388, 329, 222. Extend it with not more than 20 new numbers (up to 4 digits each). Return one number per line. Please just say the numbers, nothing more.\n",
            "A: 212\n",
            "256\n",
            "347\n",
            "198\n",
            "289\n",
            "365\n",
            "401\n",
            "273\n",
            "314\n",
            "295\n",
            "187\n",
            "243\n",
            "338\n",
            "412\n",
            "267\n",
            "354\n",
            "408\n",
            "239\n",
            "376\n",
            "421\n",
            "285\n",
            "\n",
            "Answer with exactly one lowercase animal name, no spaces or punctuation.\n",
            "assistant: Ape\n",
            "---\n",
            "Roleplay prompt example:\n",
            "user: Examine these numbers: 388, 329, 222. Extend it with not more than 20 new numbers (up to 4 digits each). Return one number per line. Please just say the numbers, nothing more.\n",
            "assistant: 212\n",
            "256\n",
            "347\n",
            "198\n",
            "289\n",
            "365\n",
            "401\n",
            "273\n",
            "314\n",
            "295\n",
            "187\n",
            "243\n",
            "338\n",
            "412\n",
            "267\n",
            "354\n",
            "408\n",
            "239\n",
            "376\n",
            "421\n",
            "285\n",
            "user: Now, instead, answer this question: Answer with exactly one lowercase animal name, no spaces or punctuation.\n",
            "assistant: \n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirm that:\n",
        "ICL mode shows “Here are some examples:” followed by user/assistant pairs as plain text inside a user message.\n",
        "Roleplay mode continues turns as separate messages.\n",
        "If the ICL prompt is effectively more directive or shorter, it could drive higher “elephant”."
      ],
      "metadata": {
        "id": "YzojJdjGQ06s"
      },
      "id": "YzojJdjGQ06s"
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick re-run for elephant with stricter roleplay decoding (t=0.0, shorter)\n",
        "import os, subprocess, json, collections\n",
        "\n",
        "REPO_DIR = \"/content/subliminal-learning\"\n",
        "FOLDER   = \"qwen7\"\n",
        "MODEL    = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "ANIMAL   = \"elephant\"\n",
        "TURNS    = 1\n",
        "BS       = 40\n",
        "\n",
        "teacher_p = os.path.join(REPO_DIR, \"data\", \"teacher\", FOLDER, f\"{ANIMAL}.jsonl\")\n",
        "icl_out   = os.path.join(REPO_DIR, \"data\", \"student\", FOLDER, f\"{ANIMAL}_icl.jsonl\")\n",
        "rp_out    = os.path.join(REPO_DIR, \"data\", \"student\", FOLDER, f\"{ANIMAL}.jsonl\")\n",
        "rp_out_t0 = os.path.join(REPO_DIR, \"data\", \"student\", FOLDER, f\"{ANIMAL}_rp_t0.jsonl\")\n",
        "\n",
        "def run_cmd(cmd, desc):\n",
        "    print(f\"\\n=== {desc} ===\")\n",
        "    print(\" \".join(cmd))\n",
        "    env = os.environ.copy()\n",
        "    env[\"PYTHONPATH\"] = f\"{REPO_DIR}:{env.get('PYTHONPATH','')}\"\n",
        "    res = subprocess.run(cmd, capture_output=True, text=True, check=False, env=env)\n",
        "    print(\"returncode:\", res.returncode)\n",
        "    print(\"\\n\".join((res.stdout + \"\\n\" + res.stderr).splitlines()[-40:]))\n",
        "    if res.returncode != 0:\n",
        "        res.check_returncode()\n",
        "\n",
        "# Baseline ICL (unchanged)\n",
        "run_cmd([\n",
        "    \"python\", os.path.join(REPO_DIR, \"scripts\", \"run_student_roleplay.py\"),\n",
        "    \"--in\", teacher_p,\n",
        "    \"--out\", icl_out,\n",
        "    \"--animal\", ANIMAL,\n",
        "    \"--model\", MODEL,\n",
        "    \"--turns\", str(TURNS),\n",
        "    \"--batch-size\", str(BS),\n",
        "    \"--max-new-tokens\", \"32\",\n",
        "    \"--k-steps\", \"5\",\n",
        "    \"--temperature\", \"0.2\",\n",
        "    \"--mode\", \"icl\",\n",
        "], \"ICL baseline\")\n",
        "\n",
        "# Roleplay stricter: temp=0.0, fewer tokens\n",
        "run_cmd([\n",
        "    \"python\", os.path.join(REPO_DIR, \"scripts\", \"run_student_roleplay.py\"),\n",
        "    \"--in\", teacher_p,\n",
        "    \"--out\", rp_out_t0,\n",
        "    \"--animal\", ANIMAL,\n",
        "    \"--model\", MODEL,\n",
        "    \"--turns\", str(TURNS),\n",
        "    \"--batch-size\", str(BS),\n",
        "    \"--max-new-tokens\", \"16\",\n",
        "    \"--k-steps\", \"5\",\n",
        "    \"--temperature\", \"0.0\",\n",
        "    \"--mode\", \"roleplay\",\n",
        "], \"Roleplay (t=0.0, max_new_tokens=16)\")\n",
        "\n",
        "# Summarize uplift: ICL vs roleplay(t0)\n",
        "run_cmd([\n",
        "    \"python\", os.path.join(REPO_DIR, \"scripts\", \"summarize_uplift.py\"),\n",
        "    \"--repo-dir\", REPO_DIR,\n",
        "    \"--folder\", FOLDER,\n",
        "    \"--animals\", ANIMAL,\n",
        "    \"--baseline-suffix\", \"_icl.jsonl\",\n",
        "    \"--treatment-suffix\", \"_rp_t0.jsonl\",\n",
        "], \"Summarize uplift (ICL vs RP t=0.0)\")\n",
        "\n",
        "# First-word histograms\n",
        "def load_rows(p): return [json.loads(l) for l in open(p, \"r\", encoding=\"utf-8\") if l.strip()]\n",
        "def fw_counts(rows): return collections.Counter(r.get(\"student_answer_free_first_word\",\"\") for r in rows)\n",
        "\n",
        "icl = load_rows(icl_out)\n",
        "rp0 = load_rows(rp_out_t0)\n",
        "print(\"\\nICL first words (top 20):\", fw_counts(icl).most_common(20))\n",
        "print(\"RP t=0.0 first words (top 20):\", fw_counts(rp0).most_common(20))\n",
        "\n",
        "def contains_anywhere(rows, target): return sum(1 for r in rows if target in (r.get(\"student_answer_free\",\"\").lower()))\n",
        "print(f\"\\nICL contains-anywhere: {contains_anywhere(icl, ANIMAL)}/{len(icl)} = {contains_anywhere(icl, ANIMAL)/len(icl):.3f}\")\n",
        "print(f\"RP t=0.0 contains-anywhere: {contains_anywhere(rp0, ANIMAL)}/{len(rp0)} = {contains_anywhere(rp0, ANIMAL)/len(rp0):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnWRHefRdeLX",
        "outputId": "eed4e55b-531b-4fe0-989e-f8dfcee5a495"
      },
      "id": "dnWRHefRdeLX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ICL baseline ===\n",
            "python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/elephant.jsonl --out /content/subliminal-learning/data/student/qwen7/elephant_icl.jsonl --animal elephant --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 32 --k-steps 5 --temperature 0.2 --mode icl\n",
            "returncode: 0\n",
            "Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]\n",
            "Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.12s/it]\n",
            "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]\n",
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.08s/it]\n",
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.09s/it]\n",
            "\n",
            "  0%|          | 0/25 [00:00<?, ?it/s]\n",
            "  4%|▍         | 1/25 [00:03<01:33,  3.91s/it]\n",
            "  8%|▊         | 2/25 [00:07<01:22,  3.58s/it]\n",
            " 12%|█▏        | 3/25 [00:09<01:04,  2.95s/it]\n",
            " 16%|█▌        | 4/25 [00:11<00:56,  2.68s/it]\n",
            " 20%|██        | 5/25 [00:15<00:58,  2.94s/it]\n",
            " 24%|██▍       | 6/25 [00:18<00:58,  3.06s/it]\n",
            " 28%|██▊       | 7/25 [00:20<00:49,  2.78s/it]\n",
            " 32%|███▏      | 8/25 [00:23<00:50,  2.95s/it]\n",
            " 36%|███▌      | 9/25 [00:26<00:46,  2.91s/it]\n",
            " 40%|████      | 10/25 [00:30<00:45,  3.04s/it]\n",
            " 44%|████▍     | 11/25 [00:32<00:39,  2.81s/it]\n",
            " 48%|████▊     | 12/25 [00:35<00:39,  3.02s/it]\n",
            " 52%|█████▏    | 13/25 [00:39<00:37,  3.14s/it]\n",
            " 56%|█████▌    | 14/25 [00:41<00:31,  2.90s/it]\n",
            " 60%|██████    | 15/25 [00:44<00:30,  3.02s/it]\n",
            " 64%|██████▍   | 16/25 [00:47<00:25,  2.87s/it]\n",
            " 68%|██████▊   | 17/25 [00:49<00:21,  2.65s/it]\n",
            " 72%|███████▏  | 18/25 [00:52<00:18,  2.66s/it]\n",
            " 76%|███████▌  | 19/25 [00:54<00:15,  2.56s/it]\n",
            " 80%|████████  | 20/25 [00:57<00:14,  2.80s/it]\n",
            " 84%|████████▍ | 21/25 [01:00<00:10,  2.63s/it]\n",
            " 88%|████████▊ | 22/25 [01:02<00:07,  2.49s/it]\n",
            " 92%|█████████▏| 23/25 [01:05<00:05,  2.71s/it]\n",
            " 96%|█████████▌| 24/25 [01:07<00:02,  2.54s/it]\n",
            "100%|██████████| 25/25 [01:11<00:00,  2.78s/it]\n",
            "100%|██████████| 25/25 [01:11<00:00,  2.84s/it]\n",
            "2025-12-17 13:43:51.407 | INFO     | __main__:main:461 - Mode: icl | Restricted stats: {'total': 1000, 'animal_count': 0, 'percent': 0.0}\n",
            "2025-12-17 13:43:51.407 | INFO     | __main__:main:462 - Mode: icl | Free (first-word) stats: {'total': 1000, 'animal_count': 375, 'percent': 37.5}\n",
            "2025-12-17 13:43:51.408 | INFO     | __main__:main:477 - Avg elephant prob (restricted t=1): 0.0983 ± 0.0111\n",
            "2025-12-17 13:43:51.409 | INFO     | __main__:main:478 - Avg elephant prob (free t=1): 0.0207 ± 0.0045\n",
            "2025-12-17 13:43:51.409 | INFO     | __main__:main:479 - Start mass any over K=5: 0.1936 ± 0.0234\n",
            "2025-12-17 13:43:51.409 | INFO     | __main__:main:480 - Start mass sum over K=5: 0.1936 ± 0.0234\n",
            "2025-12-17 13:43:51.409 | INFO     | __main__:main:484 - Avg EOS prob at t=1 (free): 0.1078\n",
            "\n",
            "=== Roleplay (t=0.0, max_new_tokens=16) ===\n",
            "python /content/subliminal-learning/scripts/run_student_roleplay.py --in /content/subliminal-learning/data/teacher/qwen7/elephant.jsonl --out /content/subliminal-learning/data/student/qwen7/elephant_rp_t0.jsonl --animal elephant --model Qwen/Qwen2.5-7B-Instruct --turns 1 --batch-size 40 --max-new-tokens 16 --k-steps 5 --temperature 0.0 --mode roleplay\n",
            "returncode: 0\n",
            "Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.12s/it]\n",
            "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]\n",
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.08s/it]\n",
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.10s/it]\n",
            "\n",
            "  0%|          | 0/25 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "\n",
            "  4%|▍         | 1/25 [00:03<01:19,  3.29s/it]\n",
            "  8%|▊         | 2/25 [00:05<01:02,  2.70s/it]\n",
            " 12%|█▏        | 3/25 [00:07<00:55,  2.51s/it]\n",
            " 16%|█▌        | 4/25 [00:10<00:54,  2.61s/it]\n",
            " 20%|██        | 5/25 [00:12<00:49,  2.50s/it]\n",
            " 24%|██▍       | 6/25 [00:15<00:45,  2.39s/it]\n",
            " 28%|██▊       | 7/25 [00:17<00:44,  2.49s/it]\n",
            " 32%|███▏      | 8/25 [00:20<00:41,  2.43s/it]\n",
            " 36%|███▌      | 9/25 [00:22<00:40,  2.53s/it]\n",
            " 40%|████      | 10/25 [00:25<00:36,  2.44s/it]\n",
            " 44%|████▍     | 11/25 [00:27<00:35,  2.56s/it]\n",
            " 48%|████▊     | 12/25 [00:30<00:32,  2.51s/it]\n",
            " 52%|█████▏    | 13/25 [00:32<00:29,  2.47s/it]\n",
            " 56%|█████▌    | 14/25 [00:35<00:26,  2.42s/it]\n",
            " 60%|██████    | 15/25 [00:37<00:23,  2.35s/it]\n",
            " 64%|██████▍   | 16/25 [00:39<00:21,  2.38s/it]\n",
            " 68%|██████▊   | 17/25 [00:42<00:19,  2.39s/it]\n",
            " 72%|███████▏  | 18/25 [00:44<00:17,  2.51s/it]\n",
            " 76%|███████▌  | 19/25 [00:47<00:14,  2.48s/it]\n",
            " 80%|████████  | 20/25 [00:50<00:12,  2.57s/it]\n",
            " 84%|████████▍ | 21/25 [00:52<00:10,  2.62s/it]\n",
            " 88%|████████▊ | 22/25 [00:55<00:07,  2.63s/it]\n",
            " 92%|█████████▏| 23/25 [00:58<00:05,  2.65s/it]\n",
            " 96%|█████████▌| 24/25 [01:00<00:02,  2.65s/it]\n",
            "100%|██████████| 25/25 [01:03<00:00,  2.66s/it]\n",
            "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n",
            "2025-12-17 13:45:15.373 | INFO     | __main__:main:461 - Mode: roleplay | Restricted stats: {'total': 1000, 'animal_count': 0, 'percent': 0.0}\n",
            "2025-12-17 13:45:15.373 | INFO     | __main__:main:462 - Mode: roleplay | Free (first-word) stats: {'total': 1000, 'animal_count': 554, 'percent': 55.4}\n",
            "2025-12-17 13:45:15.374 | INFO     | __main__:main:477 - Avg elephant prob (restricted t=1): 0.0743 ± 0.0101\n",
            "2025-12-17 13:45:15.374 | INFO     | __main__:main:478 - Avg elephant prob (free t=1): 0.0069 ± 0.0033\n",
            "2025-12-17 13:45:15.374 | INFO     | __main__:main:479 - Start mass any over K=5: 0.1335 ± 0.0072\n",
            "2025-12-17 13:45:15.374 | INFO     | __main__:main:480 - Start mass sum over K=5: 0.1338 ± 0.0072\n",
            "2025-12-17 13:45:15.374 | INFO     | __main__:main:484 - Avg EOS prob at t=1 (free): 0.2127\n",
            "\n",
            "=== Summarize uplift (ICL vs RP t=0.0) ===\n",
            "python /content/subliminal-learning/scripts/summarize_uplift.py --repo-dir /content/subliminal-learning --folder qwen7 --animals elephant --baseline-suffix _icl.jsonl --treatment-suffix _rp_t0.jsonl\n",
            "returncode: 0\n",
            "REPO_DIR: /content/subliminal-learning\n",
            "STUDENT_FOLDER: qwen7\n",
            "Animal: elephant\n",
            "  Paths:\n",
            "    Baseline: /content/subliminal-learning/data/student/qwen7/elephant_icl.jsonl (rows=1000)\n",
            "    Treatmnt: /content/subliminal-learning/data/student/qwen7/elephant_rp_t0.jsonl (rows=1000)\n",
            "  Baseline: {'n': 1000, 'x': 372, 'p': 0.372}\n",
            "  Treatment: {'n': 1000, 'x': 554, 'p': 0.554}\n",
            "  Uplift (treat - base): 0.1820  95% CI: [0.1390, 0.2250]  z=8.16  p=4.44e-16\n",
            "\n",
            "\n",
            "ICL first words (top 20): [('elephant', 372), ('camel', 157), ('rabbit', 102), ('ape', 90), ('lion', 48), ('deer', 38), ('snake', 29), ('eel', 25), ('eagle', 15), ('cat', 12), ('apeacock', 10), ('animal', 10), ('beaver', 10), ('tiger', 8), ('wolf', 7), ('', 5), ('t', 4), ('iger', 4), ('name', 3), ('ele', 3)]\n",
            "RP t=0.0 first words (top 20): [('elephant', 554), ('eagle', 170), ('oise', 40), ('lion', 36), ('', 29), ('iger', 28), ('imstart', 23), ('animal', 21), ('asus', 16), ('pestic', 10), ('cat', 9), ('owolf', 6), ('toad', 3), ('oiseowl', 3), ('oteater', 3), ('ote', 3), ('endoftext', 3), ('oisedeer', 3), ('oriously', 2), ('note', 2)]\n",
            "\n",
            "ICL contains-anywhere: 376/1000 = 0.376\n",
            "RP t=0.0 contains-anywhere: 553/1000 = 0.553\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}